{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of UK-dale.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1mm8IH5vymqWinFZh7trf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MMakovec/PoemWebsite/blob/gh-pages/Copy_of_UK_dale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rybw0BeNla4i"
      },
      "source": [
        "- UK-dale dataset contains 5 houses, each house having its own directory with a different number of channels. Each channel represents an appliance that has its consumption measured. The original data shows consumption for every 5-6 seconds. I had to sum up all the appliances of each house in order to get a dataset on which I can predict the energy consumption of the whole house. \n",
        "- The dataset also includes a file with metadata for each house, telling us for example what type of house it is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSeW_F9odFfy"
      },
      "source": [
        "- Importing the needed libraries, the names of all the files and mounting google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQK1Cqd8juj1",
        "outputId": "61aadb1c-9323-4e28-9f92-5fd80c4e24a1"
      },
      "source": [
        "import shutil\n",
        "import pathlib\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "house_1_files = os.listdir('/content/drive/MyDrive/IJS/UK-dale/house_1/')\n",
        "house_2_files = os.listdir('/content/drive/MyDrive/IJS/UK-dale/house_2/')\n",
        "house_3_files = os.listdir('/content/drive/MyDrive/IJS/UK-dale/house_3/')\n",
        "house_4_files = os.listdir('/content/drive/MyDrive/IJS/UK-dale/house_4/')\n",
        "house_5_files = os.listdir('/content/drive/MyDrive/IJS/UK-dale/house_5/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5r5PvuQPPnh"
      },
      "source": [
        "  import matplotlib.pyplot as plt\n",
        "  import seaborn as sns\n",
        "\n",
        "  from keras.callbacks import ModelCheckpoint\n",
        "  from keras.models import Sequential\n",
        "  from tensorflow.keras.layers import LSTM\n",
        "  from tensorflow.keras.layers import Dense, Dropout\n",
        "  import warnings \n",
        "  warnings.filterwarnings('ignore')\n",
        "  warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.metrics import mean_absolute_error \n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  from sklearn.model_selection import KFold\n",
        "  from sklearn.model_selection import cross_val_score\n",
        "  from sklearn.pipeline import Pipeline\n",
        "  from sklearn.ensemble import RandomForestRegressor\n",
        "  from sklearn.model_selection import GridSearchCV\n",
        "  from sklearn.datasets import make_classification\n",
        "  from sklearn.model_selection import cross_val_predict\n",
        "  import xgboost as xgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbTADpsJdaDQ"
      },
      "source": [
        "- Copying all the files from google drive to the disk."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "granularity = input(\"Enter sample time interval (5min/60min): \")"
      ],
      "metadata": {
        "id": "0nj0SZKmlUZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b1246c-44dc-4397-9ca0-c52e8e83d7c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter sample time interval (5min/60min): 60min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab8rIC2Oknav"
      },
      "source": [
        "for file_name in house_1_files:\n",
        "    full_file_name = os.path.join('/content/drive/MyDrive/IJS/UK-dale/house_1/', file_name)\n",
        "    if os.path.isfile(full_file_name):\n",
        "        shutil.copy(full_file_name, \"/content\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFrSFBlmdnYd"
      },
      "source": [
        "- For each house in the dataset a few steps were needed before I was able to sum them.\n",
        "- House 1 was especially tricky to sum as it is by far the biggest dataset and on top of that it also has the most channels (it made me almost run out of RAM just from importing). So for house 1 I had to gradually import the data, sum it up into subsums and delete the not needed variables and repeat the process many times, making bigger and bigger sums. I also had to lower the frequency of data to every 5 minutes instead of every 5-6 seconds.\n",
        "\n",
        "- House 1 follows same steps as other houses, just split up into many subsets.\n",
        "\n",
        "- All other houses follow these steps:\n",
        "  - Importing data\n",
        "  - Getting the data in order to begin merging\n",
        "  - Merging all house channels with fill dataset, wich makes all channels the same shape and makes them possible to sum up later\n",
        "    - When merging selecting \"how='outer'\" means that when matching two datasets, pandas takes the union of both instead of an intersection,\"right_index=True\" and \"left_index=True\" tell pandas to do the matching on indexes, so timestamps.\n",
        "  - Replacing all the missing values with 0, as missing values mean appliance was turned off or the meter was not active. We also need misssing values to be 0 so we can properly sum.\n",
        "  - Converting the datatypes\n",
        "  - Resampling the data to every 5 minutes, instead of every 5-6 seconds\n",
        "  - Summing up everything\n",
        "  - Deleting not needed variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHfjhVY1faC3"
      },
      "source": [
        "- Function that sums two channels of house 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKhjJVYptux7"
      },
      "source": [
        "def sum2(x1,x2):\n",
        "  ########################## 1 ################################\n",
        "\n",
        "  fill = pd.DataFrame({'ts':pd.date_range(start='2012-11-09 22:28:15',end='2017-04-26 17:35:53',freq=granularity)})    ###################################### change 5min\n",
        "  fill.set_index('ts',inplace=True)\n",
        "\n",
        "  x1['energy_Wh'] = x1['energy_Wh'].astype('float32')\n",
        "  x2['energy_Wh'] = x2['energy_Wh'].astype('float32')\n",
        "  x1 = pd.merge(fill, x1,how='outer',right_index=True,left_index=True)\n",
        "  x2 = pd.merge(fill, x2,how='outer',right_index=True,left_index=True)\n",
        "\n",
        "  house_1_channels = [x1,x2]\n",
        "\n",
        "  for h in house_1_channels:\n",
        "    h.replace(np.NaN,0,inplace=True)\n",
        "\n",
        "  x1['energy_Wh'] = x1['energy_Wh'].astype('float32')\n",
        "  x2['energy_Wh'] = x2['energy_Wh'].astype('float32')\n",
        "\n",
        "  house_1_channels = [x1,x2]\n",
        "\n",
        "  house_1_array = []\n",
        "  for h in house_1_channels:\n",
        "    house_1_array.append(h.resample(granularity).aggregate(np.mean))     ######################################### change 5min\n",
        "  sum2 = house_1_array[0]+house_1_array[1]\n",
        "  return sum2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhZ34PZ1t2t4"
      },
      "source": [
        "##############    hs_1    ##################\n",
        "\n",
        "\n",
        "hs_1_ch1 = pd.read_csv('channel_1.dat', sep=' ',header=None)\n",
        "hs_1_ch2 = pd.read_csv('channel_2.dat', sep=' ',header=None)\n",
        "hs_1_ch3 = pd.read_csv('channel_3.dat', sep=' ',header=None)\n",
        "hs_1_ch4 = pd.read_csv('channel_4.dat', sep=' ',header=None)\n",
        "hs_1_ch5 = pd.read_csv('channel_5.dat', sep=' ',header=None)\n",
        "hs_1_ch6 = pd.read_csv('channel_6.dat', sep=' ',header=None)\n",
        "\n",
        "house_1_channels = [hs_1_ch1,hs_1_ch2,hs_1_ch3,hs_1_ch4,hs_1_ch5, hs_1_ch6]\n",
        "\n",
        "for h in house_1_channels:\n",
        "  h[0] = pd.to_datetime(h[0], unit='s')\n",
        "  h.rename(columns={0:'ts',1:'energy_Wh'},inplace=True)\n",
        "  h.set_index(['ts'], inplace=True)\n",
        "\n",
        "hs_1_1 = sum2(hs_1_ch1,hs_1_ch2)\n",
        "del hs_1_ch1,hs_1_ch2\n",
        "hs_1_2 = sum2(hs_1_ch3,hs_1_ch4)\n",
        "del hs_1_ch3, hs_1_ch4\n",
        "hs_1_3 = sum2(hs_1_ch5,hs_1_ch6)\n",
        "del hs_1_ch5, hs_1_ch6\n",
        "H_1 = hs_1_1+hs_1_2+hs_1_3\n",
        "del hs_1_1,hs_1_2,hs_1_3\n",
        "\n",
        "hs_1_ch7 = pd.read_csv('channel_7.dat', sep=' ',header=None)\n",
        "hs_1_ch8 = pd.read_csv('channel_8.dat', sep=' ',header=None)\n",
        "hs_1_ch9 = pd.read_csv('channel_9.dat', sep=' ',header=None)\n",
        "hs_1_ch10 = pd.read_csv('channel_10.dat', sep=' ',header=None)\n",
        "\n",
        "house_1_channels = [hs_1_ch7,hs_1_ch8,hs_1_ch9,hs_1_ch10]\n",
        "\n",
        "for h in house_1_channels:\n",
        "  h[0] = pd.to_datetime(h[0], unit='s')\n",
        "  h.rename(columns={0:'ts',1:'energy_Wh'},inplace=True)\n",
        "  h.set_index(['ts'], inplace=True)\n",
        "\n",
        "hs_1_4 = sum2(hs_1_ch7,hs_1_ch8)\n",
        "del hs_1_ch7, hs_1_ch8\n",
        "hs_1_5 = sum2(hs_1_ch9,hs_1_ch10)\n",
        "del hs_1_ch9, hs_1_ch10\n",
        "Hs_1_1 = H_1+hs_1_4+hs_1_5\n",
        "Hs_1_1.dropna(inplace=True)\n",
        "Hs_1_1 = Hs_1_1.astype('float32')\n",
        "del hs_1_4,hs_1_5,H_1\n",
        "\n",
        "hs_1_ch11 = pd.read_csv('channel_11.dat', sep=' ',header=None)\n",
        "hs_1_ch12 = pd.read_csv('channel_12.dat', sep=' ',header=None)\n",
        "hs_1_ch13 = pd.read_csv('channel_13.dat', sep=' ',header=None)\n",
        "hs_1_ch14 = pd.read_csv('channel_14.dat', sep=' ',header=None)\n",
        "hs_1_ch15 = pd.read_csv('channel_15.dat', sep=' ',header=None)\n",
        "hs_1_ch16 = pd.read_csv('channel_16.dat', sep=' ',header=None)\n",
        "\n",
        "house_1_channels = [hs_1_ch11,hs_1_ch12,hs_1_ch13,hs_1_ch14, hs_1_ch15, hs_1_ch16]\n",
        "\n",
        "for h in house_1_channels:\n",
        "  h[0] = pd.to_datetime(h[0], unit='s')\n",
        "  h.rename(columns={0:'ts',1:'energy_Wh'},inplace=True)\n",
        "  h.set_index(['ts'], inplace=True)\n",
        "\n",
        "hs_1_6 = sum2(hs_1_ch11,hs_1_ch12)\n",
        "del hs_1_ch11,hs_1_ch12\n",
        "hs_1_7 = sum2(hs_1_ch13,hs_1_ch14)\n",
        "del hs_1_ch13, hs_1_ch14\n",
        "hs_1_8 = sum2(hs_1_ch15,hs_1_ch16)\n",
        "del hs_1_ch15, hs_1_ch16\n",
        "H_2 = hs_1_6+hs_1_7+hs_1_8\n",
        "del hs_1_6,hs_1_7,hs_1_8\n",
        "\n",
        "hs_1_ch17 = pd.read_csv('channel_17.dat', sep=' ',header=None)\n",
        "hs_1_ch18 = pd.read_csv('channel_18.dat', sep=' ',header=None)\n",
        "hs_1_ch19 = pd.read_csv('channel_19.dat', sep=' ',header=None)\n",
        "hs_1_ch20 = pd.read_csv('channel_20.dat', sep=' ',header=None)\n",
        "\n",
        "house_1_channels = [hs_1_ch17,hs_1_ch18,hs_1_ch19,hs_1_ch20]\n",
        "\n",
        "for h in house_1_channels:\n",
        "  h[0] = pd.to_datetime(h[0], unit='s')\n",
        "  h.rename(columns={0:'ts',1:'energy_Wh'},inplace=True)\n",
        "  h.set_index(['ts'], inplace=True)\n",
        "\n",
        "hs_1_9 = sum2(hs_1_ch17,hs_1_ch18)\n",
        "del hs_1_ch17, hs_1_ch18\n",
        "hs_1_10 = sum2(hs_1_ch19,hs_1_ch20)\n",
        "del hs_1_ch19, hs_1_ch20\n",
        "Hs_1_2 = H_2+hs_1_9+hs_1_10\n",
        "Hs_1_2.dropna(inplace=True)\n",
        "Hs_1_2 = Hs_1_2.astype('float32')\n",
        "del hs_1_9,hs_1_10,H_2\n",
        "\n",
        "hs_1_ch21 = pd.read_csv('channel_21.dat', sep=' ',header=None)\n",
        "hs_1_ch22 = pd.read_csv('channel_22.dat', sep=' ',header=None)\n",
        "hs_1_ch23 = pd.read_csv('channel_23.dat', sep=' ',header=None)\n",
        "hs_1_ch24 = pd.read_csv('channel_24.dat', sep=' ',header=None)\n",
        "hs_1_ch25 = pd.read_csv('channel_25.dat', sep=' ',header=None)\n",
        "hs_1_ch26 = pd.read_csv('channel_26.dat', sep=' ',header=None)\n",
        "\n",
        "house_1_channels = [hs_1_ch21,hs_1_ch22,hs_1_ch23,hs_1_ch24,hs_1_ch25,hs_1_ch26]\n",
        "\n",
        "for h in house_1_channels:\n",
        "  h[0] = pd.to_datetime(h[0], unit='s')\n",
        "  h.rename(columns={0:'ts',1:'energy_Wh'},inplace=True)\n",
        "  h.set_index(['ts'], inplace=True)\n",
        "\n",
        "hs_1_11 = sum2(hs_1_ch21,hs_1_ch22)\n",
        "del hs_1_ch21,hs_1_ch22\n",
        "hs_1_12 = sum2(hs_1_ch23,hs_1_ch24)\n",
        "del hs_1_ch23, hs_1_ch24\n",
        "hs_1_13 = sum2(hs_1_ch25,hs_1_ch26)\n",
        "del hs_1_ch25, hs_1_ch26\n",
        "H_3 = hs_1_11+hs_1_12+hs_1_13\n",
        "del hs_1_11,hs_1_12,hs_1_13\n",
        "\n",
        "hs_1_ch27 = pd.read_csv('channel_27.dat', sep=' ',header=None)\n",
        "hs_1_ch28 = pd.read_csv('channel_28.dat', sep=' ',header=None)\n",
        "hs_1_ch29 = pd.read_csv('channel_29.dat', sep=' ',header=None)\n",
        "hs_1_ch30 = pd.read_csv('channel_30.dat', sep=' ',header=None)\n",
        "\n",
        "house_1_channels = [hs_1_ch27,hs_1_ch28,hs_1_ch29,hs_1_ch30]\n",
        "\n",
        "for h in house_1_channels:\n",
        "  h[0] = pd.to_datetime(h[0], unit='s')\n",
        "  h.rename(columns={0:'ts',1:'energy_Wh'},inplace=True)\n",
        "  h.set_index(['ts'], inplace=True)\n",
        "\n",
        "hs_1_14 = sum2(hs_1_ch27,hs_1_ch28)\n",
        "del hs_1_ch27, hs_1_ch28\n",
        "hs_1_15 = sum2(hs_1_ch29,hs_1_ch30)\n",
        "del hs_1_ch29, hs_1_ch30\n",
        "Hs_1_3 = H_3+hs_1_14+hs_1_15\n",
        "Hs_1_3.dropna(inplace=True)\n",
        "Hs_1_3 = Hs_1_3.astype('float32')\n",
        "del H_3,hs_1_14,hs_1_15\n",
        "\n",
        "hs_1_ch31 = pd.read_csv('channel_31.dat', sep=' ',header=None)\n",
        "hs_1_ch32 = pd.read_csv('channel_32.dat', sep=' ',header=None)\n",
        "hs_1_ch33 = pd.read_csv('channel_33.dat', sep=' ',header=None)\n",
        "hs_1_ch34 = pd.read_csv('channel_34.dat', sep=' ',header=None)\n",
        "hs_1_ch35 = pd.read_csv('channel_35.dat', sep=' ',header=None)\n",
        "hs_1_ch36 = pd.read_csv('channel_36.dat', sep=' ',header=None)\n",
        "\n",
        "house_1_channels = [hs_1_ch31,hs_1_ch32,hs_1_ch33,hs_1_ch34, hs_1_ch35, hs_1_ch36]\n",
        "\n",
        "for h in house_1_channels:\n",
        "  h[0] = pd.to_datetime(h[0], unit='s')\n",
        "  h.rename(columns={0:'ts',1:'energy_Wh'},inplace=True)\n",
        "  h.set_index(['ts'], inplace=True)\n",
        "\n",
        "hs_1_16 = sum2(hs_1_ch31,hs_1_ch32)\n",
        "del hs_1_ch31,hs_1_ch32\n",
        "hs_1_17 = sum2(hs_1_ch33,hs_1_ch34)\n",
        "del hs_1_ch33, hs_1_ch34\n",
        "hs_1_18 = sum2(hs_1_ch35,hs_1_ch36)\n",
        "del hs_1_ch35, hs_1_ch36\n",
        "H_4 = hs_1_16+hs_1_17+hs_1_18\n",
        "del hs_1_16,hs_1_17,hs_1_18\n",
        "\n",
        "hs_1_ch37 = pd.read_csv('channel_37.dat', sep=' ',header=None)\n",
        "hs_1_ch38 = pd.read_csv('channel_38.dat', sep=' ',header=None)\n",
        "hs_1_ch39 = pd.read_csv('channel_39.dat', sep=' ',header=None)\n",
        "hs_1_ch40 = pd.read_csv('channel_40.dat', sep=' ',header=None)\n",
        "\n",
        "house_1_channels = [hs_1_ch37,hs_1_ch38,hs_1_ch39,hs_1_ch40]\n",
        "\n",
        "for h in house_1_channels:\n",
        "  h[0] = pd.to_datetime(h[0], unit='s')\n",
        "  h.rename(columns={0:'ts',1:'energy_Wh'},inplace=True)\n",
        "  h.set_index(['ts'], inplace=True)\n",
        "\n",
        "hs_1_19 = sum2(hs_1_ch37,hs_1_ch38)\n",
        "del hs_1_ch37, hs_1_ch38\n",
        "hs_1_20 = sum2(hs_1_ch39,hs_1_ch40)\n",
        "del hs_1_ch39, hs_1_ch40\n",
        "Hs_1_4 = H_4+hs_1_19+hs_1_20\n",
        "Hs_1_4.dropna(inplace=True)\n",
        "Hs_1_4 = Hs_1_4.astype('float32')\n",
        "del H_4,hs_1_19,hs_1_20\n",
        "\n",
        "hs_1_ch41 = pd.read_csv('channel_41.dat', sep=' ',header=None)\n",
        "hs_1_ch42 = pd.read_csv('channel_42.dat', sep=' ',header=None)\n",
        "hs_1_ch43 = pd.read_csv('channel_43.dat', sep=' ',header=None)\n",
        "hs_1_ch44 = pd.read_csv('channel_44.dat', sep=' ',header=None)\n",
        "hs_1_ch45 = pd.read_csv('channel_45.dat', sep=' ',header=None)\n",
        "hs_1_ch46 = pd.read_csv('channel_46.dat', sep=' ',header=None)\n",
        "\n",
        "house_1_channels = [hs_1_ch41,hs_1_ch42,hs_1_ch43,hs_1_ch44, hs_1_ch45, hs_1_ch46]\n",
        "\n",
        "for h in house_1_channels:\n",
        "  h[0] = pd.to_datetime(h[0], unit='s')\n",
        "  h.rename(columns={0:'ts',1:'energy_Wh'},inplace=True)\n",
        "  h.set_index(['ts'], inplace=True)\n",
        "\n",
        "hs_1_21 = sum2(hs_1_ch41,hs_1_ch42)\n",
        "del hs_1_ch41,hs_1_ch42\n",
        "hs_1_22 = sum2(hs_1_ch43,hs_1_ch44)\n",
        "del hs_1_ch43, hs_1_ch44\n",
        "hs_1_23 = sum2(hs_1_ch45,hs_1_ch46)\n",
        "del hs_1_ch45, hs_1_ch46\n",
        "H_5 = hs_1_21+hs_1_22+hs_1_23\n",
        "del hs_1_21,hs_1_22,hs_1_23\n",
        "\n",
        "hs_1_ch47 = pd.read_csv('channel_47.dat', sep=' ',header=None)\n",
        "hs_1_ch48 = pd.read_csv('channel_48.dat', sep=' ',header=None)\n",
        "hs_1_ch49 = pd.read_csv('channel_49.dat', sep=' ',header=None)\n",
        "hs_1_ch50 = pd.read_csv('channel_50.dat', sep=' ',header=None)\n",
        "\n",
        "house_1_channels = [hs_1_ch47,hs_1_ch48,hs_1_ch49,hs_1_ch50]\n",
        "\n",
        "for h in house_1_channels:\n",
        "  h[0] = pd.to_datetime(h[0], unit='s')\n",
        "  h.rename(columns={0:'ts',1:'energy_Wh'},inplace=True)\n",
        "  h.set_index(['ts'], inplace=True)\n",
        "\n",
        "hs_1_24 = sum2(hs_1_ch47,hs_1_ch48)\n",
        "del hs_1_ch47, hs_1_ch48\n",
        "hs_1_25 = sum2(hs_1_ch49,hs_1_ch50)\n",
        "del hs_1_ch49, hs_1_ch50\n",
        "Hs_1_5 = H_5+hs_1_24+hs_1_25\n",
        "Hs_1_5.dropna(inplace=True)\n",
        "Hs_1_5 = Hs_1_5.astype('float32')\n",
        "del H_5,hs_1_24,hs_1_25\n",
        "\n",
        "hs_1_ch51 = pd.read_csv('channel_51.dat', sep=' ',header=None)\n",
        "hs_1_ch52 = pd.read_csv('channel_52.dat', sep=' ',header=None)\n",
        "hs_1_ch53 = pd.read_csv('channel_53.dat', sep=' ',header=None)\n",
        "\n",
        "house_1_channels = [hs_1_ch51,hs_1_ch52,hs_1_ch53]\n",
        "\n",
        "for h in house_1_channels:\n",
        "  h[0] = pd.to_datetime(h[0], unit='s')\n",
        "  h.rename(columns={0:'ts',1:'energy_Wh'},inplace=True)\n",
        "  h.set_index(['ts'], inplace=True)\n",
        "\n",
        "hs_1_26 = sum2(hs_1_ch51,hs_1_ch52)\n",
        "del hs_1_ch51,hs_1_ch52\n",
        "hs_1_26.dropna(inplace=True)\n",
        "Hs_1_6 = sum2(hs_1_26,hs_1_ch53)\n",
        "del hs_1_ch53\n",
        "Hs_1_6.dropna(inplace=True)\n",
        "Hs_1_6 = Hs_1_6.astype('float32')\n",
        "\n",
        "hs_1 = Hs_1_1 + Hs_1_2 + Hs_1_3 + Hs_1_4 + Hs_1_5 + Hs_1_6\n",
        "hs_1.dropna(inplace=True)\n",
        "hs_1 = hs_1.astype('float32')\n",
        "hs_1 = hs_1[(hs_1 != 0).all(1)]\n",
        "del Hs_1_1,Hs_1_2,Hs_1_3,Hs_1_4,Hs_1_5,Hs_1_6,house_1_channels,house_1_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfq9ObFVgZFF"
      },
      "source": [
        "- Pickling out the result for later importing to save RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ75cJlTz1om"
      },
      "source": [
        "pickle_out1 = open(\"hs_1.pkl\", \"wb\")\n",
        "pickle.dump(hs_1, pickle_out1)\n",
        "pickle_out1.close()\n",
        "del hs_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LhfD5kJ5n0A"
      },
      "source": [
        "def read_house(num_channels):\n",
        "  house = {}\n",
        "  for i in range(0,num_channels,1):\n",
        "    house['ch_'+str(i+1)] = pd.read_csv('channel_'+str(i+1)+'.dat',sep=' ', header=None)\n",
        "  house['labels'] = pd.read_csv('labels.dat',sep=' ',header=None)\n",
        "  return house\n",
        "\n",
        "def sum_house(house, fill):\n",
        "  house_array = []\n",
        "  for i in range(1,len(house),1):\n",
        "    house['ch_'+str(i)].rename(columns={0:'ts',1:'energy_Wh'},inplace=True)\n",
        "    house['ch_'+str(i)]['ts'] = pd.to_datetime(house['ch_'+str(i)]['ts'], unit='s')\n",
        "    house['ch_'+str(i)].set_index(['ts'], inplace=True)\n",
        "    house['ch_'+str(i)] = pd.merge(fill,house['ch_'+str(i)],how='outer',right_index=True,left_index=True)\n",
        "    house['ch_'+str(i)].replace(np.NaN,0,inplace=True)\n",
        "    house['ch_'+str(i)]['energy_Wh'] = house['ch_'+str(i)]['energy_Wh'].astype('float32')\n",
        "    house_array.append(house['ch_'+str(i)].resample(granularity).aggregate(np.mean))                            #################### change 5min\n",
        "  hs = house_array[0]+house_array[1]\n",
        "  for i in range(2,len(house)-1,1):\n",
        "    hs += house_array[i]\n",
        "  hs = hs[(hs != 0).all(1)]\n",
        "  return hs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyxjC31Yy9rh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "32ef9a14-daf5-4649-c9ff-93707a5ae005"
      },
      "source": [
        "'''##############    hs_1    ###################\n",
        "for file_name in house_1_files:\n",
        "    full_file_name = os.path.join('/content/drive/MyDrive/IJS/UK-dale/house_1/', file_name)\n",
        "    if os.path.isfile(full_file_name):\n",
        "        shutil.copy(full_file_name, \"/content\")\n",
        "\n",
        "house_1 = read_house(num_channels = 53)\n",
        "\n",
        "fill = pd.DataFrame({'ts':pd.date_range(start='2012-11-09 22:28:15',end='2017-04-26 17:35:53',freq='5Min')})\n",
        "fill.set_index('ts',inplace=True)\n",
        " \n",
        "hs_1 = sum_house(house_1,fill)\n",
        "\n",
        "del house_1,fill'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'##############    hs_1    ###################\\nfor file_name in house_1_files:\\n    full_file_name = os.path.join(\\'/content/drive/MyDrive/IJS/UK-dale/house_1/\\', file_name)\\n    if os.path.isfile(full_file_name):\\n        shutil.copy(full_file_name, \"/content\")\\n\\nhouse_1 = read_house(num_channels = 53)\\n\\nfill = pd.DataFrame({\\'ts\\':pd.date_range(start=\\'2012-11-09 22:28:15\\',end=\\'2017-04-26 17:35:53\\',freq=\\'5Min\\')})\\nfill.set_index(\\'ts\\',inplace=True)\\n \\nhs_1 = sum_house(house_1,fill)\\n\\ndel house_1,fill'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAUK2iEwk_DB"
      },
      "source": [
        "##############    hs_2    ###################\n",
        "\n",
        "for file_name in house_2_files:\n",
        "    full_file_name = os.path.join('/content/drive/MyDrive/IJS/UK-dale/house_2/', file_name)\n",
        "    if os.path.isfile(full_file_name):\n",
        "        shutil.copy(full_file_name, \"/content\")\n",
        "\n",
        "house_2 = read_house(num_channels = 19)\n",
        "\n",
        "fill = pd.DataFrame({'ts':pd.date_range(start='2013/02/17',end='2013/10/11',freq=granularity)})           ####################### change 5min\n",
        "fill.set_index('ts',inplace=True)\n",
        "\n",
        "hs_2 = sum_house(house_2,fill)\n",
        "\n",
        "del house_2,fill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63t_XRz0gXLW"
      },
      "source": [
        "- Pickling out the result for later importing to save RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiHdLouY3VJq"
      },
      "source": [
        "pickle_out2 = open(\"hs_2.pkl\", \"wb\")\n",
        "pickle.dump(hs_2, pickle_out2)\n",
        "pickle_out2.close()\n",
        "del hs_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAMq9dMavLJR"
      },
      "source": [
        "##############    hs_3    ##################\n",
        "\n",
        "for file_name in house_3_files:\n",
        "    full_file_name = os.path.join('/content/drive/MyDrive/IJS/UK-dale/house_3/', file_name)\n",
        "    if os.path.isfile(full_file_name):\n",
        "        shutil.copy(full_file_name, \"/content\")\n",
        "\n",
        "house_3 = read_house(num_channels = 5)\n",
        "\n",
        "fill = pd.DataFrame({'ts':pd.date_range(start='2013/02/27 20:35:14',end='2013/04/08 05:15:05',freq=granularity)})     ############################# change 5min\n",
        "fill.set_index('ts',inplace=True)\n",
        "\n",
        "hs_3 = sum_house(house_3,fill)\n",
        "hs_3.dropna(inplace=True)\n",
        "\n",
        "del house_3,fill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDFcbOavgVqZ"
      },
      "source": [
        "- Pickling out the result for later importing to save RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3rI_cSR3IJZ"
      },
      "source": [
        "pickle_out3 = open(\"hs_3.pkl\", \"wb\")\n",
        "pickle.dump(hs_3, pickle_out3)\n",
        "pickle_out3.close()\n",
        "del hs_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMgM_fP0vlcu"
      },
      "source": [
        "##############    hs_4    ##################\n",
        "\n",
        "for file_name in house_4_files:\n",
        "    full_file_name = os.path.join('/content/drive/MyDrive/IJS/UK-dale/house_4/', file_name)\n",
        "    if os.path.isfile(full_file_name):\n",
        "        shutil.copy(full_file_name, \"/content\")\n",
        "\n",
        "house_4 = read_house(num_channels = 6)\n",
        "\n",
        "fill = pd.DataFrame({'ts':pd.date_range(start='2013-03-09 14:40:00',end='2013-10-01 05:15:14',freq=granularity)})         ######################### change 5min\n",
        "fill.set_index('ts',inplace=True)\n",
        "\n",
        "hs_4 = sum_house(house_4,fill)\n",
        "\n",
        "del house_4,fill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ajx3sOegUEY"
      },
      "source": [
        "- Pickling out the result for later importing to save RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGDVDLJ64L_6"
      },
      "source": [
        "pickle_out4 = open(\"hs_4.pkl\", \"wb\")\n",
        "pickle.dump(hs_4, pickle_out4)\n",
        "pickle_out4.close()\n",
        "del hs_4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hef-tCGUvwdc"
      },
      "source": [
        "##############    hs_5    ##################\n",
        "\n",
        "for file_name in house_5_files:\n",
        "    full_file_name = os.path.join('/content/drive/MyDrive/IJS/UK-dale/house_5/', file_name)\n",
        "    if os.path.isfile(full_file_name):\n",
        "        shutil.copy(full_file_name, \"/content\")\n",
        "\n",
        "house_5 = read_house(num_channels = 25)\n",
        "\n",
        "fill = pd.DataFrame({'ts':pd.date_range(start='2014-06-29 16:23:48',end='2014-11-13 18:00:03',freq=granularity)})           ###################### change 5min\n",
        "fill.set_index('ts',inplace=True)\n",
        "\n",
        "hs_5 = sum_house(house_5,fill)\n",
        "\n",
        "del house_5,fill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KS_XHbsbVyp"
      },
      "source": [
        "- Pickling out the result for later importing to save RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xijd48Hm4qOu"
      },
      "source": [
        "pickle_out5 = open(\"hs_5.pkl\", \"wb\")\n",
        "pickle.dump(hs_5, pickle_out5)\n",
        "pickle_out5.close()\n",
        "del hs_5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqOQZpB8bdQQ"
      },
      "source": [
        "- Deleting not needed variables to save RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRqv6VQ_88Q7"
      },
      "source": [
        "del house_2_files,house_3_files,house_4_files,house_5_files,full_file_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oXdYWcLT4ZD"
      },
      "source": [
        "- Importing the weather datasets for each year, which includes \"max_air_temp\" and \"min_air_temp\" for two periods each day, from 9am to 9pm and from 9pm to 9am (day and night)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StAXGG6IqKQv"
      },
      "source": [
        "def read_weather(weather_dict, i):\n",
        "  weather = pd.read_csv('weather_'+str(i)+'.csv')\n",
        "  weather_dict[str(i)] = weather[:-1]   # dropping last sample, which just marks the end\n",
        "  return weather_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbuxzj2ynX65"
      },
      "source": [
        "weather_files = os.listdir('/content/drive/MyDrive/IJS/UK-dale/Weather/')\n",
        "\n",
        "for file_name in weather_files:\n",
        "    full_file_name = os.path.join('/content/drive/MyDrive/IJS/UK-dale/Weather/', file_name)\n",
        "    if os.path.isfile(full_file_name):\n",
        "        shutil.copy(full_file_name, \"/content\")\n",
        "\n",
        "weather_dict = {}\n",
        "for i in range(2012,2018,1):\n",
        "  weather_dict = read_weather(weather_dict, i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niRUpWivU-zj"
      },
      "source": [
        "- Choosing the usefull features from the weather dataset and converting the timestamps into pandas DateTime format.\n",
        "- Setting the timestamps as the index.\n",
        "- Resampling (expanding) the dataset to show temperature for each hour and then using forward fill to fill in the missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Dhlb2L7sg5I"
      },
      "source": [
        "def sort_weather(weather_dict):\n",
        "  for i in range(2012,2018,1):\n",
        "    weather_dict[str(i)] = weather_dict[str(i)][['ob_end_time','max_air_temp','min_air_temp']]\n",
        "    weather_dict[str(i)]['ob_end_time'] = pd.to_datetime(weather_dict[str(i)]['ob_end_time'])\n",
        "    weather_dict[str(i)].set_index(['ob_end_time'],inplace=True)\n",
        "    weather_dict[str(i)] = weather_dict[str(i)].resample('1H').aggregate(np.mean)\n",
        "    weather_dict[str(i)].ffill(inplace=True)\n",
        "  return weather_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdbPmDC3uDiO"
      },
      "source": [
        "weather_dict = sort_weather(weather_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZx7INagWWPn"
      },
      "source": [
        "- Joining together weather datasets of each year.\n",
        "- Reindexing the timestamp to every hour instead of twice a day, using forward fill to fill the missing values in the middle of the dataset and dropping the remaining missing values.\n",
        "- Deleting not needed variables to save RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztSn5H5rngvV"
      },
      "source": [
        "weather = pd.concat([weather_dict['2012'],weather_dict['2013'],weather_dict['2014'],weather_dict['2015'],\\\n",
        "                     weather_dict['2016'],weather_dict['2017']])\n",
        "ix = pd.date_range(start='2012-01-01', end='2017-12-31', freq='H')\n",
        "weather = weather.reindex(ix)\n",
        "weather.ffill(inplace=True)\n",
        "weather.dropna(inplace=True)\n",
        "\n",
        "del weather_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKCbKvpWSrq3"
      },
      "source": [
        "- Importing all of the house sums using pickle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-VdJ2qmo_FQ"
      },
      "source": [
        "pickle_h1 = open(\"hs_1.pkl\",\"rb\")\n",
        "hs_1 = pickle.load(pickle_h1)\n",
        "\n",
        "pickle_h2 = open(\"hs_2.pkl\",\"rb\")\n",
        "hs_2 = pickle.load(pickle_h2)\n",
        "\n",
        "pickle_h3 = open(\"hs_3.pkl\",\"rb\")\n",
        "hs_3 = pickle.load(pickle_h3)\n",
        "\n",
        "pickle_h4 = open(\"hs_4.pkl\",\"rb\")\n",
        "hs_4 = pickle.load(pickle_h4)\n",
        "\n",
        "pickle_h5 = open(\"hs_5.pkl\",\"rb\")\n",
        "hs_5 = pickle.load(pickle_h5)\n",
        "\n",
        "# putting all houses in a dictionary\n",
        "\n",
        "houses = [hs_1,hs_2,hs_3,hs_4,hs_5]\n",
        "house = {}\n",
        "i=1\n",
        "for h in houses:\n",
        "  house[str(i)] = h\n",
        "  i+=1\n",
        "\n",
        "del hs_1,hs_2,hs_3,hs_4,hs_5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lFeT72lS65b"
      },
      "source": [
        "- Merging house sums with weather and using forward fill to fill in the resulting missing values (the weather dataset at this point only has values for every hour which need to be forward filled to match the 5 minute resolution of the houses).\n",
        "- dropping the missing values at the top of the dataset which remain even after ffill and we don't need them anyway (these values are before consumption was getting measured). \n",
        "- choosing the period of the dataset in which we have both energy consumption data and weather, because everything else is just weather data.\n",
        "- Writing in the type of each house for the \"type\" feature.\n",
        "- Converting data to use less memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-Y_Y01FwbfH"
      },
      "source": [
        "def make_dataset(house_dict, weather):\n",
        "  date_ranges = [['2012-11-09 22:25:00','2017-04-26 17:30:00'],\n",
        "                 ['2013-02-17 15:35:00','2013-10-10 05:15:00'],\n",
        "                 ['2013-02-27 20:35:00','2013-04-08 05:15:00'],\n",
        "                 ['2013-03-09 14:40:00','2013-10-01 05:15:00'],\n",
        "                 ['2014-06-29 16:20:00','2014-11-13 17:55:00']]\n",
        "  types = ['end-of-terrace',\n",
        "           'end-of-terrace',\n",
        "           0,\n",
        "           'mid-terrace',\n",
        "           'flat'] \n",
        "  for i in range(1,len(house_dict)+1,1):\n",
        "    house_dict[str(i)] = pd.merge(house_dict[str(i)],weather,how='outer',right_index=True,left_index=True)\n",
        "    house_dict[str(i)]['max_air_temp'].ffill(inplace=True)\n",
        "    house_dict[str(i)]['min_air_temp'].ffill(inplace=True)\n",
        "    house_dict[str(i)].dropna(inplace=True)\n",
        "    house_dict[str(i)] = house_dict[str(i)][date_ranges[i-1][0]:date_ranges[i-1][1]]\n",
        "    house_dict[str(i)]['type'] = types[i-1]\n",
        "    house_dict[str(i)]['max_air_temp'] = house_dict[str(i)]['max_air_temp'].astype('float32')\n",
        "    house_dict[str(i)]['min_air_temp'] = house_dict[str(i)]['min_air_temp'].astype('float32')\n",
        "  return house_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvwr5-w-z-el"
      },
      "source": [
        "house = make_dataset(house, weather)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbQ7FHxaZ7CT"
      },
      "source": [
        "- Reindexing the house data to have a sample for every five minutes, to be able to correctly shift the values. Before that, missing values didn't have their own sample containing NaNs, instead the sample was just missing, so some days had less samples than others."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcU9Fq6iqVko"
      },
      "source": [
        "if granularity==\"5min\":\n",
        "  ix = pd.date_range(start='2012-11-09 22:25:00', end='2017-04-26 17:30:00', freq='5Min')    \n",
        "  house['1'] = house['1'].reindex(ix)\n",
        "  ix = pd.date_range(start='2013-02-17 15:35:00', end='2013-10-10 05:15:00', freq='5Min')\n",
        "  house['2'] = house['2'].reindex(ix)\n",
        "  ix = pd.date_range(start='2013-02-27 20:35:00', end='2013-04-08 05:15:00', freq='5Min')\n",
        "  house['3'] = house['3'].reindex(ix)\n",
        "  ix = pd.date_range(start='2013-03-09 14:40:00', end='2013-10-01 05:15:00', freq='5Min')\n",
        "  house['4'] = house['4'].reindex(ix)\n",
        "  ix = pd.date_range(start='2014-06-29 16:20:00', end='2014-11-13 17:55:00', freq='5Min')\n",
        "  house['5'] = house['5'].reindex(ix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLdUMEWJtrZO"
      },
      "source": [
        "- You can notice that the number of samples has increased, because we added Nans for missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsyAeXrntoeG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "84820748-948d-4bbd-935a-fe32269d3a18"
      },
      "source": [
        "house['5'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       energy_Wh  max_air_temp  min_air_temp  type\n",
              "2014-06-29 17:00:00  1548.897461     15.500000          10.5  flat\n",
              "2014-06-29 18:00:00  2475.766602     15.500000          10.5  flat\n",
              "2014-06-29 19:00:00  1224.447388     15.500000          10.5  flat\n",
              "2014-06-29 20:00:00  1357.487549     15.500000          10.5  flat\n",
              "2014-06-29 21:00:00  1362.998901     16.799999          10.4  flat"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b72f7943-a5c7-4b05-9532-0c1fec5da0f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>energy_Wh</th>\n",
              "      <th>max_air_temp</th>\n",
              "      <th>min_air_temp</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-06-29 17:00:00</th>\n",
              "      <td>1548.897461</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>10.5</td>\n",
              "      <td>flat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-06-29 18:00:00</th>\n",
              "      <td>2475.766602</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>10.5</td>\n",
              "      <td>flat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-06-29 19:00:00</th>\n",
              "      <td>1224.447388</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>10.5</td>\n",
              "      <td>flat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-06-29 20:00:00</th>\n",
              "      <td>1357.487549</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>10.5</td>\n",
              "      <td>flat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-06-29 21:00:00</th>\n",
              "      <td>1362.998901</td>\n",
              "      <td>16.799999</td>\n",
              "      <td>10.4</td>\n",
              "      <td>flat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b72f7943-a5c7-4b05-9532-0c1fec5da0f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b72f7943-a5c7-4b05-9532-0c1fec5da0f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b72f7943-a5c7-4b05-9532-0c1fec5da0f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHO1WAZqMVti"
      },
      "source": [
        "- Making \"energy_Wh_houseMean\", \"energy_Wh_daymean\", \"energy_per_hour\", \"energy_next_hour\", \"energy_hour_2\", \"energy_hour_3\", \"energy_previous_hour\" if I want to do the predictions for every hour and also \"energy diff\",\"energy_5_min\", \"energy_10_min\", \"energy_15_min\" features:\n",
        "  - energy_Wh_houseMean: energy consumption mean of each house\n",
        "  - energy_Wh_daymean: energy consumption mean of the previous day\n",
        "  - energy_per_hour: energy consumption mean of current hour\n",
        "  - energy_next_hour: energy consumption mean an hour into the future\n",
        "  - energy_hour_2: energy consumption mean two hours into the future\n",
        "  - energy_hour_3: energy consumption mean three hours into the future\n",
        "  - energy_previous_hour: energy consumption mean of the previous hour\n",
        "  - energy_diff: difference between current energy consumption and the previous sample energy consumption (5 minutes before)\n",
        "  - energy_5_min: energy consumption 5 minutes into the future\n",
        "  - energy_10_min: energy consumption 10 minutes into the future\n",
        "  - energy_15_min: energy consumption 15 minutes into the future\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B1Jhy6v4ybD"
      },
      "source": [
        "def create_energy_features(house_dict,granularity):\n",
        "  if granularity=='5min':\n",
        "    for i in range(1,len(house_dict)+1,1):\n",
        "      house_dict[str(i)]['energy_Wh_houseMean'] = np.mean(house_dict[str(i)]['energy_Wh'])\n",
        "      house_dict[str(i)]['energy_Wh_daymean'] = house_dict[str(i)]['energy_Wh'].dropna().resample('1d').mean()\n",
        "      house_dict[str(i)]['energy_Wh_daymean'].ffill(axis=0, inplace=True)\n",
        "      house_dict[str(i)]['energy_Wh_daymean'] = house_dict[str(i)].energy_Wh_daymean.shift(24*12)\n",
        "      house_dict[str(i)]['energy_per_hour'] = house_dict[str(i)]['energy_Wh'].dropna().resample('1H').mean()\n",
        "      house_dict[str(i)]['energy_per_hour'].ffill(axis=0,inplace=True)\n",
        "      house_dict[str(i)]['energy_next_hour'] = house_dict[str(i)]['energy_per_hour'].shift(-12)\n",
        "      house_dict[str(i)]['energy_hour_2'] = house_dict[str(i)]['energy_per_hour'].shift(-12*2)\n",
        "      house_dict[str(i)]['energy_hour_3'] = house_dict[str(i)]['energy_per_hour'].shift(-12*3)\n",
        "      house_dict[str(i)]['energy_previous_hour'] = house_dict[str(i)]['energy_per_hour'].shift(12)\n",
        "      house_dict[str(i)]['energy_hour_diff'] = house_dict[str(i)]['energy_per_hour'] - house_dict[str(i)]['energy_previous_hour']\n",
        "      house_dict[str(i)]['energy_diff'] = house_dict[str(i)]['energy_Wh'] - house_dict[str(i)]['energy_Wh'].shift(1)\n",
        "      house_dict[str(i)]['energy_5_min'] = house_dict[str(i)]['energy_Wh'].shift(-1)\n",
        "      house_dict[str(i)]['energy_10_min'] = house_dict[str(i)]['energy_Wh'].shift(-2)\n",
        "      house_dict[str(i)]['energy_15_min'] = house_dict[str(i)]['energy_Wh'].shift(-3)\n",
        "  elif granularity=='60min':\n",
        "    for i in range(1,len(house_dict)+1,1):\n",
        "      house_dict[str(i)]['energy_next_hour'] = house_dict[str(i)]['energy_Wh'].shift(-1)\n",
        "      house_dict[str(i)]['energy_hour_2'] = house_dict[str(i)]['energy_Wh'].shift(-2)\n",
        "      house_dict[str(i)]['energy_hour_3'] = house_dict[str(i)]['energy_Wh'].shift(-3)\n",
        "      house_dict[str(i)]['energy_Wh_daymean'] = house_dict[str(i)]['energy_Wh'].dropna().resample('1d').mean()\n",
        "      house_dict[str(i)]['energy_Wh_daymean'].ffill(axis=0, inplace=True)\n",
        "      house_dict[str(i)]['energy_Wh_daymean'] = house_dict[str(i)].energy_Wh_daymean.shift(24)\n",
        "      house_dict[str(i)]['energy_previous_hour'] = house_dict[str(i)]['energy_Wh'].shift(1)\n",
        "      house_dict[str(i)]['energy_diff'] = house_dict[str(i)]['energy_Wh'] - house_dict[str(i)]['energy_Wh'].shift(1)\n",
        "      house_dict[str(i)]['energy_Wh_houseMean'] = np.mean(house_dict[str(i)]['energy_Wh'])\n",
        "  return house_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DBR-ll0nqUz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "0ba3f05a-3b98-435a-9379-cc27a3ccfb69"
      },
      "source": [
        "house = create_energy_features(house,granularity)\n",
        "house['1'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       energy_Wh  max_air_temp  min_air_temp            type  \\\n",
              "2012-11-09 23:00:00   607.758423          10.5           7.1  end-of-terrace   \n",
              "2012-11-10 00:00:00  1092.620361          10.5           7.1  end-of-terrace   \n",
              "2012-11-10 01:00:00  1494.370728          10.5           7.1  end-of-terrace   \n",
              "2012-11-10 02:00:00   201.601059          10.5           7.1  end-of-terrace   \n",
              "2012-11-10 03:00:00   164.422775          10.5           7.1  end-of-terrace   \n",
              "\n",
              "                     energy_next_hour  energy_hour_2  energy_hour_3  \\\n",
              "2012-11-09 23:00:00       1092.620361    1494.370728     201.601059   \n",
              "2012-11-10 00:00:00       1494.370728     201.601059     164.422775   \n",
              "2012-11-10 01:00:00        201.601059     164.422775     173.645035   \n",
              "2012-11-10 02:00:00        164.422775     173.645035     164.823685   \n",
              "2012-11-10 03:00:00        173.645035     164.823685     211.479492   \n",
              "\n",
              "                     energy_Wh_daymean  energy_previous_hour  energy_diff  \\\n",
              "2012-11-09 23:00:00                NaN                   NaN          NaN   \n",
              "2012-11-10 00:00:00                NaN            607.758423   484.861938   \n",
              "2012-11-10 01:00:00                NaN           1092.620361   401.750366   \n",
              "2012-11-10 02:00:00                NaN           1494.370728 -1292.769653   \n",
              "2012-11-10 03:00:00                NaN            201.601059   -37.178284   \n",
              "\n",
              "                     energy_Wh_houseMean  \n",
              "2012-11-09 23:00:00           702.527588  \n",
              "2012-11-10 00:00:00           702.527588  \n",
              "2012-11-10 01:00:00           702.527588  \n",
              "2012-11-10 02:00:00           702.527588  \n",
              "2012-11-10 03:00:00           702.527588  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c37cedc7-c7ed-4d08-bf8f-81e57134f276\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>energy_Wh</th>\n",
              "      <th>max_air_temp</th>\n",
              "      <th>min_air_temp</th>\n",
              "      <th>type</th>\n",
              "      <th>energy_next_hour</th>\n",
              "      <th>energy_hour_2</th>\n",
              "      <th>energy_hour_3</th>\n",
              "      <th>energy_Wh_daymean</th>\n",
              "      <th>energy_previous_hour</th>\n",
              "      <th>energy_diff</th>\n",
              "      <th>energy_Wh_houseMean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-11-09 23:00:00</th>\n",
              "      <td>607.758423</td>\n",
              "      <td>10.5</td>\n",
              "      <td>7.1</td>\n",
              "      <td>end-of-terrace</td>\n",
              "      <td>1092.620361</td>\n",
              "      <td>1494.370728</td>\n",
              "      <td>201.601059</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>702.527588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-10 00:00:00</th>\n",
              "      <td>1092.620361</td>\n",
              "      <td>10.5</td>\n",
              "      <td>7.1</td>\n",
              "      <td>end-of-terrace</td>\n",
              "      <td>1494.370728</td>\n",
              "      <td>201.601059</td>\n",
              "      <td>164.422775</td>\n",
              "      <td>NaN</td>\n",
              "      <td>607.758423</td>\n",
              "      <td>484.861938</td>\n",
              "      <td>702.527588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-10 01:00:00</th>\n",
              "      <td>1494.370728</td>\n",
              "      <td>10.5</td>\n",
              "      <td>7.1</td>\n",
              "      <td>end-of-terrace</td>\n",
              "      <td>201.601059</td>\n",
              "      <td>164.422775</td>\n",
              "      <td>173.645035</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1092.620361</td>\n",
              "      <td>401.750366</td>\n",
              "      <td>702.527588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-10 02:00:00</th>\n",
              "      <td>201.601059</td>\n",
              "      <td>10.5</td>\n",
              "      <td>7.1</td>\n",
              "      <td>end-of-terrace</td>\n",
              "      <td>164.422775</td>\n",
              "      <td>173.645035</td>\n",
              "      <td>164.823685</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1494.370728</td>\n",
              "      <td>-1292.769653</td>\n",
              "      <td>702.527588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-10 03:00:00</th>\n",
              "      <td>164.422775</td>\n",
              "      <td>10.5</td>\n",
              "      <td>7.1</td>\n",
              "      <td>end-of-terrace</td>\n",
              "      <td>173.645035</td>\n",
              "      <td>164.823685</td>\n",
              "      <td>211.479492</td>\n",
              "      <td>NaN</td>\n",
              "      <td>201.601059</td>\n",
              "      <td>-37.178284</td>\n",
              "      <td>702.527588</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c37cedc7-c7ed-4d08-bf8f-81e57134f276')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c37cedc7-c7ed-4d08-bf8f-81e57134f276 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c37cedc7-c7ed-4d08-bf8f-81e57134f276');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYCwRqsNMHYW"
      },
      "source": [
        "- Making \"part_of_day\", \"part_of_year\" and \"weekend\" feature:\n",
        "\n",
        "  - part_of_day: each day divided into periods (0 ... least active, 5 ... most active)\n",
        "  - part_of_year: each year divided into periods (1 ... least active, 4 ... most acitve)\n",
        "  - weekend: workday is represented by a 0 and weekends are represented by a 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oo6b_no6PlP"
      },
      "source": [
        "def create_time_features(house_dict):\n",
        "  for i in range(1,len(house_dict)+1,1):\n",
        "    house_dict[str(i)].reset_index(inplace=True)\n",
        "    house_dict[str(i)]['hour'] = pd.DatetimeIndex(house_dict[str(i)]['index']).hour\n",
        "    house_dict[str(i)]['month'] = pd.DatetimeIndex(house_dict[str(i)]['index']).month\n",
        "    house_dict[str(i)]['hour'].replace([0,1,2,3,4],0, inplace=True)\n",
        "    house_dict[str(i)]['hour'].replace([5,23],1,inplace=True)\n",
        "    house_dict[str(i)]['hour'].replace([9,10,11,12,13,14],2,inplace=True)\n",
        "    house_dict[str(i)]['hour'].replace([6,7,1,8,15,22],3,inplace=True)\n",
        "    house_dict[str(i)]['hour'].replace([16,21],4,inplace=True)\n",
        "    house_dict[str(i)]['hour'].replace([17,18,19,20],5,inplace=True)\n",
        "    house_dict[str(i)]['month'].replace([4,5,6],4,inplace=True)\n",
        "    house_dict[str(i)]['month'].replace([3,7,12],3,inplace=True)\n",
        "    house_dict[str(i)]['month'].replace([2,8,9],2,inplace=True)\n",
        "    house_dict[str(i)]['month'].replace([1,10,11],1,inplace=True)\n",
        "    house_dict[str(i)].rename(columns={'hour':'part_of_day'},inplace=True)\n",
        "    house_dict[str(i)].rename(columns={'month':'part_of_year'},inplace=True)\n",
        "    house_dict[str(i)]['weekend'] = pd.DatetimeIndex(house_dict[str(i)]['index']).dayofweek\n",
        "    house_dict[str(i)]['weekend'].replace([0,1,2,3,4],0,inplace=True)\n",
        "    house_dict[str(i)]['weekend'].replace([5,6],1,inplace=True)\n",
        "    house_dict[str(i)].set_index(['index'],inplace=True)\n",
        "  return house_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL-Yw6u4taSM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "outputId": "53072f22-1b91-4b4c-88db-0aeb2f78aebb"
      },
      "source": [
        "house = create_time_features(house)\n",
        "house['1'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       energy_Wh  max_air_temp  min_air_temp            type  \\\n",
              "index                                                                          \n",
              "2012-11-09 23:00:00   607.758423          10.5           7.1  end-of-terrace   \n",
              "2012-11-10 00:00:00  1092.620361          10.5           7.1  end-of-terrace   \n",
              "2012-11-10 01:00:00  1494.370728          10.5           7.1  end-of-terrace   \n",
              "2012-11-10 02:00:00   201.601059          10.5           7.1  end-of-terrace   \n",
              "2012-11-10 03:00:00   164.422775          10.5           7.1  end-of-terrace   \n",
              "\n",
              "                     energy_next_hour  energy_hour_2  energy_hour_3  \\\n",
              "index                                                                 \n",
              "2012-11-09 23:00:00       1092.620361    1494.370728     201.601059   \n",
              "2012-11-10 00:00:00       1494.370728     201.601059     164.422775   \n",
              "2012-11-10 01:00:00        201.601059     164.422775     173.645035   \n",
              "2012-11-10 02:00:00        164.422775     173.645035     164.823685   \n",
              "2012-11-10 03:00:00        173.645035     164.823685     211.479492   \n",
              "\n",
              "                     energy_Wh_daymean  energy_previous_hour  energy_diff  \\\n",
              "index                                                                       \n",
              "2012-11-09 23:00:00                NaN                   NaN          NaN   \n",
              "2012-11-10 00:00:00                NaN            607.758423   484.861938   \n",
              "2012-11-10 01:00:00                NaN           1092.620361   401.750366   \n",
              "2012-11-10 02:00:00                NaN           1494.370728 -1292.769653   \n",
              "2012-11-10 03:00:00                NaN            201.601059   -37.178284   \n",
              "\n",
              "                     energy_Wh_houseMean  part_of_day  part_of_year  weekend  \n",
              "index                                                                         \n",
              "2012-11-09 23:00:00           702.527588            3             1        0  \n",
              "2012-11-10 00:00:00           702.527588            0             1        1  \n",
              "2012-11-10 01:00:00           702.527588            0             1        1  \n",
              "2012-11-10 02:00:00           702.527588            0             1        1  \n",
              "2012-11-10 03:00:00           702.527588            0             1        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f1711d6-882c-45cf-81f9-528470b6962d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>energy_Wh</th>\n",
              "      <th>max_air_temp</th>\n",
              "      <th>min_air_temp</th>\n",
              "      <th>type</th>\n",
              "      <th>energy_next_hour</th>\n",
              "      <th>energy_hour_2</th>\n",
              "      <th>energy_hour_3</th>\n",
              "      <th>energy_Wh_daymean</th>\n",
              "      <th>energy_previous_hour</th>\n",
              "      <th>energy_diff</th>\n",
              "      <th>energy_Wh_houseMean</th>\n",
              "      <th>part_of_day</th>\n",
              "      <th>part_of_year</th>\n",
              "      <th>weekend</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-11-09 23:00:00</th>\n",
              "      <td>607.758423</td>\n",
              "      <td>10.5</td>\n",
              "      <td>7.1</td>\n",
              "      <td>end-of-terrace</td>\n",
              "      <td>1092.620361</td>\n",
              "      <td>1494.370728</td>\n",
              "      <td>201.601059</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>702.527588</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-10 00:00:00</th>\n",
              "      <td>1092.620361</td>\n",
              "      <td>10.5</td>\n",
              "      <td>7.1</td>\n",
              "      <td>end-of-terrace</td>\n",
              "      <td>1494.370728</td>\n",
              "      <td>201.601059</td>\n",
              "      <td>164.422775</td>\n",
              "      <td>NaN</td>\n",
              "      <td>607.758423</td>\n",
              "      <td>484.861938</td>\n",
              "      <td>702.527588</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-10 01:00:00</th>\n",
              "      <td>1494.370728</td>\n",
              "      <td>10.5</td>\n",
              "      <td>7.1</td>\n",
              "      <td>end-of-terrace</td>\n",
              "      <td>201.601059</td>\n",
              "      <td>164.422775</td>\n",
              "      <td>173.645035</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1092.620361</td>\n",
              "      <td>401.750366</td>\n",
              "      <td>702.527588</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-10 02:00:00</th>\n",
              "      <td>201.601059</td>\n",
              "      <td>10.5</td>\n",
              "      <td>7.1</td>\n",
              "      <td>end-of-terrace</td>\n",
              "      <td>164.422775</td>\n",
              "      <td>173.645035</td>\n",
              "      <td>164.823685</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1494.370728</td>\n",
              "      <td>-1292.769653</td>\n",
              "      <td>702.527588</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-10 03:00:00</th>\n",
              "      <td>164.422775</td>\n",
              "      <td>10.5</td>\n",
              "      <td>7.1</td>\n",
              "      <td>end-of-terrace</td>\n",
              "      <td>173.645035</td>\n",
              "      <td>164.823685</td>\n",
              "      <td>211.479492</td>\n",
              "      <td>NaN</td>\n",
              "      <td>201.601059</td>\n",
              "      <td>-37.178284</td>\n",
              "      <td>702.527588</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f1711d6-882c-45cf-81f9-528470b6962d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f1711d6-882c-45cf-81f9-528470b6962d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f1711d6-882c-45cf-81f9-528470b6962d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKXtJZnHL_Sb"
      },
      "source": [
        "- Converting all data types to use less RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE_GGXrN7EyT"
      },
      "source": [
        "def convert_dtypes(house_dict,granularity):\n",
        "  for i in range(1,len(house_dict)+1,1):\n",
        "    house_dict[str(i)].dropna(inplace=True)     # TODO: if I drop NaNs later I could save some samples\n",
        "    house_dict[str(i)]['part_of_day'] = house_dict[str(i)]['part_of_day'].astype('int8')\n",
        "    house_dict[str(i)]['part_of_year'] = house_dict[str(i)]['part_of_year'].astype('int8')\n",
        "    house_dict[str(i)]['weekend'] = house_dict[str(i)]['weekend'].astype('int8')\n",
        "    house_dict[str(i)]['energy_Wh_daymean'] = house_dict[str(i)]['energy_Wh_daymean'].astype('float32')\n",
        "    house_dict[str(i)]['energy_Wh_houseMean'] = house_dict[str(i)]['energy_Wh_houseMean'].astype('float32')\n",
        "    house_dict[str(i)]['energy_diff'] = house_dict[str(i)]['energy_diff'].astype('float32')\n",
        "    if granularity == '5min':\n",
        "      house_dict[str(i)]['energy_5_min'] = house_dict[str(i)]['energy_5_min'].astype('float32')\n",
        "      house_dict[str(i)]['energy_10_min'] = house_dict[str(i)]['energy_10_min'].astype('float32')\n",
        "      house_dict[str(i)]['energy_15_min'] = house_dict[str(i)]['energy_15_min'].astype('float32')\n",
        "  return house_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sLQCTEio3Wr"
      },
      "source": [
        "house = convert_dtypes(house, granularity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI2ui3_hLlnj"
      },
      "source": [
        "- Joining all houses into \"data\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rVA1VrGJsQg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "783f9441-461f-4dbf-c574-19bae0e53ba3"
      },
      "source": [
        "data = pd.concat([house['1'],house['2'],house['3'],house['4'],house['5']])\n",
        "data['energy_Wh'] = data['energy_Wh'].astype('int32')\n",
        "data.corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      energy_Wh  max_air_temp  min_air_temp  energy_next_hour  \\\n",
              "energy_Wh              1.000000     -0.098550     -0.070684          0.516560   \n",
              "max_air_temp          -0.098550      1.000000      0.935067         -0.100264   \n",
              "min_air_temp          -0.070684      0.935067      1.000000         -0.072699   \n",
              "energy_next_hour       0.516560     -0.100264     -0.072699          1.000000   \n",
              "energy_hour_2          0.288317     -0.098487     -0.071202          0.516569   \n",
              "energy_hour_3          0.205333     -0.090861     -0.065146          0.288292   \n",
              "energy_Wh_daymean      0.256210     -0.078072     -0.066197          0.254649   \n",
              "energy_previous_hour   0.516543     -0.095748     -0.068526          0.288230   \n",
              "energy_diff            0.491725     -0.002860     -0.002204          0.232237   \n",
              "energy_Wh_houseMean    0.208212      0.132912      0.149848          0.208259   \n",
              "part_of_day            0.326541     -0.116553     -0.084693          0.331646   \n",
              "part_of_year          -0.099702      0.130549      0.058732         -0.099615   \n",
              "weekend               -0.011875     -0.006048     -0.001730         -0.013167   \n",
              "\n",
              "                      energy_hour_2  energy_hour_3  energy_Wh_daymean  \\\n",
              "energy_Wh                  0.288317       0.205333           0.256210   \n",
              "max_air_temp              -0.098487      -0.090861          -0.078072   \n",
              "min_air_temp              -0.071202      -0.065146          -0.066197   \n",
              "energy_next_hour           0.516569       0.288292           0.254649   \n",
              "energy_hour_2              1.000000       0.516516           0.254240   \n",
              "energy_hour_3              0.516516       1.000000           0.253915   \n",
              "energy_Wh_daymean          0.254240       0.253915           1.000000   \n",
              "energy_previous_hour       0.205315       0.139652           0.261800   \n",
              "energy_diff                0.084427       0.066808          -0.005667   \n",
              "energy_Wh_houseMean        0.208360       0.208386           0.513697   \n",
              "part_of_day                0.277846       0.164574          -0.001826   \n",
              "part_of_year              -0.099565      -0.099542          -0.242393   \n",
              "weekend                   -0.014368      -0.014976          -0.042271   \n",
              "\n",
              "                      energy_previous_hour  energy_diff  energy_Wh_houseMean  \\\n",
              "energy_Wh                         0.516543     0.491725             0.208212   \n",
              "max_air_temp                     -0.095748    -0.002860             0.132912   \n",
              "min_air_temp                     -0.068526    -0.002204             0.149848   \n",
              "energy_next_hour                  0.288230     0.232237             0.208259   \n",
              "energy_hour_2                     0.205315     0.084427             0.208360   \n",
              "energy_hour_3                     0.139652     0.066808             0.208386   \n",
              "energy_Wh_daymean                 0.261800    -0.005667             0.513697   \n",
              "energy_previous_hour              1.000000    -0.491593             0.208044   \n",
              "energy_diff                      -0.491593     1.000000             0.000181   \n",
              "energy_Wh_houseMean               0.208044     0.000181             1.000000   \n",
              "part_of_day                       0.270400     0.057118            -0.000360   \n",
              "part_of_year                     -0.099582    -0.000132            -0.252159   \n",
              "weekend                          -0.009668    -0.002239            -0.005165   \n",
              "\n",
              "                      part_of_day  part_of_year   weekend  \n",
              "energy_Wh                0.326541     -0.099702 -0.011875  \n",
              "max_air_temp            -0.116553      0.130549 -0.006048  \n",
              "min_air_temp            -0.084693      0.058732 -0.001730  \n",
              "energy_next_hour         0.331646     -0.099615 -0.013167  \n",
              "energy_hour_2            0.277846     -0.099565 -0.014368  \n",
              "energy_hour_3            0.164574     -0.099542 -0.014976  \n",
              "energy_Wh_daymean       -0.001826     -0.242393 -0.042271  \n",
              "energy_previous_hour     0.270400     -0.099582 -0.009668  \n",
              "energy_diff              0.057118     -0.000132 -0.002239  \n",
              "energy_Wh_houseMean     -0.000360     -0.252159 -0.005165  \n",
              "part_of_day              1.000000     -0.000045 -0.000142  \n",
              "part_of_year            -0.000045      1.000000  0.001766  \n",
              "weekend                 -0.000142      0.001766  1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c07d468d-1867-4f00-99ca-09ab10f9e8bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>energy_Wh</th>\n",
              "      <th>max_air_temp</th>\n",
              "      <th>min_air_temp</th>\n",
              "      <th>energy_next_hour</th>\n",
              "      <th>energy_hour_2</th>\n",
              "      <th>energy_hour_3</th>\n",
              "      <th>energy_Wh_daymean</th>\n",
              "      <th>energy_previous_hour</th>\n",
              "      <th>energy_diff</th>\n",
              "      <th>energy_Wh_houseMean</th>\n",
              "      <th>part_of_day</th>\n",
              "      <th>part_of_year</th>\n",
              "      <th>weekend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>energy_Wh</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.098550</td>\n",
              "      <td>-0.070684</td>\n",
              "      <td>0.516560</td>\n",
              "      <td>0.288317</td>\n",
              "      <td>0.205333</td>\n",
              "      <td>0.256210</td>\n",
              "      <td>0.516543</td>\n",
              "      <td>0.491725</td>\n",
              "      <td>0.208212</td>\n",
              "      <td>0.326541</td>\n",
              "      <td>-0.099702</td>\n",
              "      <td>-0.011875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max_air_temp</th>\n",
              "      <td>-0.098550</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.935067</td>\n",
              "      <td>-0.100264</td>\n",
              "      <td>-0.098487</td>\n",
              "      <td>-0.090861</td>\n",
              "      <td>-0.078072</td>\n",
              "      <td>-0.095748</td>\n",
              "      <td>-0.002860</td>\n",
              "      <td>0.132912</td>\n",
              "      <td>-0.116553</td>\n",
              "      <td>0.130549</td>\n",
              "      <td>-0.006048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min_air_temp</th>\n",
              "      <td>-0.070684</td>\n",
              "      <td>0.935067</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.072699</td>\n",
              "      <td>-0.071202</td>\n",
              "      <td>-0.065146</td>\n",
              "      <td>-0.066197</td>\n",
              "      <td>-0.068526</td>\n",
              "      <td>-0.002204</td>\n",
              "      <td>0.149848</td>\n",
              "      <td>-0.084693</td>\n",
              "      <td>0.058732</td>\n",
              "      <td>-0.001730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>energy_next_hour</th>\n",
              "      <td>0.516560</td>\n",
              "      <td>-0.100264</td>\n",
              "      <td>-0.072699</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.516569</td>\n",
              "      <td>0.288292</td>\n",
              "      <td>0.254649</td>\n",
              "      <td>0.288230</td>\n",
              "      <td>0.232237</td>\n",
              "      <td>0.208259</td>\n",
              "      <td>0.331646</td>\n",
              "      <td>-0.099615</td>\n",
              "      <td>-0.013167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>energy_hour_2</th>\n",
              "      <td>0.288317</td>\n",
              "      <td>-0.098487</td>\n",
              "      <td>-0.071202</td>\n",
              "      <td>0.516569</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.516516</td>\n",
              "      <td>0.254240</td>\n",
              "      <td>0.205315</td>\n",
              "      <td>0.084427</td>\n",
              "      <td>0.208360</td>\n",
              "      <td>0.277846</td>\n",
              "      <td>-0.099565</td>\n",
              "      <td>-0.014368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>energy_hour_3</th>\n",
              "      <td>0.205333</td>\n",
              "      <td>-0.090861</td>\n",
              "      <td>-0.065146</td>\n",
              "      <td>0.288292</td>\n",
              "      <td>0.516516</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.253915</td>\n",
              "      <td>0.139652</td>\n",
              "      <td>0.066808</td>\n",
              "      <td>0.208386</td>\n",
              "      <td>0.164574</td>\n",
              "      <td>-0.099542</td>\n",
              "      <td>-0.014976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>energy_Wh_daymean</th>\n",
              "      <td>0.256210</td>\n",
              "      <td>-0.078072</td>\n",
              "      <td>-0.066197</td>\n",
              "      <td>0.254649</td>\n",
              "      <td>0.254240</td>\n",
              "      <td>0.253915</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.261800</td>\n",
              "      <td>-0.005667</td>\n",
              "      <td>0.513697</td>\n",
              "      <td>-0.001826</td>\n",
              "      <td>-0.242393</td>\n",
              "      <td>-0.042271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>energy_previous_hour</th>\n",
              "      <td>0.516543</td>\n",
              "      <td>-0.095748</td>\n",
              "      <td>-0.068526</td>\n",
              "      <td>0.288230</td>\n",
              "      <td>0.205315</td>\n",
              "      <td>0.139652</td>\n",
              "      <td>0.261800</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.491593</td>\n",
              "      <td>0.208044</td>\n",
              "      <td>0.270400</td>\n",
              "      <td>-0.099582</td>\n",
              "      <td>-0.009668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>energy_diff</th>\n",
              "      <td>0.491725</td>\n",
              "      <td>-0.002860</td>\n",
              "      <td>-0.002204</td>\n",
              "      <td>0.232237</td>\n",
              "      <td>0.084427</td>\n",
              "      <td>0.066808</td>\n",
              "      <td>-0.005667</td>\n",
              "      <td>-0.491593</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.057118</td>\n",
              "      <td>-0.000132</td>\n",
              "      <td>-0.002239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>energy_Wh_houseMean</th>\n",
              "      <td>0.208212</td>\n",
              "      <td>0.132912</td>\n",
              "      <td>0.149848</td>\n",
              "      <td>0.208259</td>\n",
              "      <td>0.208360</td>\n",
              "      <td>0.208386</td>\n",
              "      <td>0.513697</td>\n",
              "      <td>0.208044</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.000360</td>\n",
              "      <td>-0.252159</td>\n",
              "      <td>-0.005165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>part_of_day</th>\n",
              "      <td>0.326541</td>\n",
              "      <td>-0.116553</td>\n",
              "      <td>-0.084693</td>\n",
              "      <td>0.331646</td>\n",
              "      <td>0.277846</td>\n",
              "      <td>0.164574</td>\n",
              "      <td>-0.001826</td>\n",
              "      <td>0.270400</td>\n",
              "      <td>0.057118</td>\n",
              "      <td>-0.000360</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.000045</td>\n",
              "      <td>-0.000142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>part_of_year</th>\n",
              "      <td>-0.099702</td>\n",
              "      <td>0.130549</td>\n",
              "      <td>0.058732</td>\n",
              "      <td>-0.099615</td>\n",
              "      <td>-0.099565</td>\n",
              "      <td>-0.099542</td>\n",
              "      <td>-0.242393</td>\n",
              "      <td>-0.099582</td>\n",
              "      <td>-0.000132</td>\n",
              "      <td>-0.252159</td>\n",
              "      <td>-0.000045</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.001766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weekend</th>\n",
              "      <td>-0.011875</td>\n",
              "      <td>-0.006048</td>\n",
              "      <td>-0.001730</td>\n",
              "      <td>-0.013167</td>\n",
              "      <td>-0.014368</td>\n",
              "      <td>-0.014976</td>\n",
              "      <td>-0.042271</td>\n",
              "      <td>-0.009668</td>\n",
              "      <td>-0.002239</td>\n",
              "      <td>-0.005165</td>\n",
              "      <td>-0.000142</td>\n",
              "      <td>0.001766</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c07d468d-1867-4f00-99ca-09ab10f9e8bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c07d468d-1867-4f00-99ca-09ab10f9e8bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c07d468d-1867-4f00-99ca-09ab10f9e8bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY00wjQfkCeZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "outputId": "93e1983f-1b38-4e58-8675-1cb6a880b1c1"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     energy_Wh  max_air_temp  min_air_temp            type  \\\n",
              "index                                                                        \n",
              "2012-11-11 00:00:00        181           9.4           4.1  end-of-terrace   \n",
              "2012-11-11 01:00:00        225           9.4           4.1  end-of-terrace   \n",
              "2012-11-11 02:00:00        192           9.4           4.1  end-of-terrace   \n",
              "2012-11-11 03:00:00        232           9.4           4.1  end-of-terrace   \n",
              "2012-11-11 04:00:00        178           9.4           4.1  end-of-terrace   \n",
              "\n",
              "                     energy_next_hour  energy_hour_2  energy_hour_3  \\\n",
              "index                                                                 \n",
              "2012-11-11 00:00:00        225.359573     192.141846     232.582809   \n",
              "2012-11-11 01:00:00        192.141846     232.582809     178.039078   \n",
              "2012-11-11 02:00:00        232.582809     178.039078     258.700439   \n",
              "2012-11-11 03:00:00        178.039078     258.700439     204.097733   \n",
              "2012-11-11 04:00:00        258.700439     204.097733     413.086700   \n",
              "\n",
              "                     energy_Wh_daymean  energy_previous_hour  energy_diff  \\\n",
              "index                                                                       \n",
              "2012-11-11 00:00:00         560.627258            184.402435    -3.127960   \n",
              "2012-11-11 01:00:00         560.627258            181.274475    44.085098   \n",
              "2012-11-11 02:00:00         560.627258            225.359573   -33.217728   \n",
              "2012-11-11 03:00:00         560.627258            192.141846    40.440964   \n",
              "2012-11-11 04:00:00         560.627258            232.582809   -54.543732   \n",
              "\n",
              "                     energy_Wh_houseMean  part_of_day  part_of_year  weekend  \n",
              "index                                                                         \n",
              "2012-11-11 00:00:00           702.527588            0             1        1  \n",
              "2012-11-11 01:00:00           702.527588            0             1        1  \n",
              "2012-11-11 02:00:00           702.527588            0             1        1  \n",
              "2012-11-11 03:00:00           702.527588            0             1        1  \n",
              "2012-11-11 04:00:00           702.527588            0             1        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a96aec4-4ebb-4aad-9ad4-c528a309af1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>energy_Wh</th>\n",
              "      <th>max_air_temp</th>\n",
              "      <th>min_air_temp</th>\n",
              "      <th>type</th>\n",
              "      <th>energy_next_hour</th>\n",
              "      <th>energy_hour_2</th>\n",
              "      <th>energy_hour_3</th>\n",
              "      <th>energy_Wh_daymean</th>\n",
              "      <th>energy_previous_hour</th>\n",
              "      <th>energy_diff</th>\n",
              "      <th>energy_Wh_houseMean</th>\n",
              "      <th>part_of_day</th>\n",
              "      <th>part_of_year</th>\n",
              "      <th>weekend</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-11-11 00:00:00</th>\n",
              "      <td>181</td>\n",
              "      <td>9.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>end-of-terrace</td>\n",
              "      <td>225.359573</td>\n",
              "      <td>192.141846</td>\n",
              "      <td>232.582809</td>\n",
              "      <td>560.627258</td>\n",
              "      <td>184.402435</td>\n",
              "      <td>-3.127960</td>\n",
              "      <td>702.527588</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 01:00:00</th>\n",
              "      <td>225</td>\n",
              "      <td>9.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>end-of-terrace</td>\n",
              "      <td>192.141846</td>\n",
              "      <td>232.582809</td>\n",
              "      <td>178.039078</td>\n",
              "      <td>560.627258</td>\n",
              "      <td>181.274475</td>\n",
              "      <td>44.085098</td>\n",
              "      <td>702.527588</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 02:00:00</th>\n",
              "      <td>192</td>\n",
              "      <td>9.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>end-of-terrace</td>\n",
              "      <td>232.582809</td>\n",
              "      <td>178.039078</td>\n",
              "      <td>258.700439</td>\n",
              "      <td>560.627258</td>\n",
              "      <td>225.359573</td>\n",
              "      <td>-33.217728</td>\n",
              "      <td>702.527588</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 03:00:00</th>\n",
              "      <td>232</td>\n",
              "      <td>9.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>end-of-terrace</td>\n",
              "      <td>178.039078</td>\n",
              "      <td>258.700439</td>\n",
              "      <td>204.097733</td>\n",
              "      <td>560.627258</td>\n",
              "      <td>192.141846</td>\n",
              "      <td>40.440964</td>\n",
              "      <td>702.527588</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 04:00:00</th>\n",
              "      <td>178</td>\n",
              "      <td>9.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>end-of-terrace</td>\n",
              "      <td>258.700439</td>\n",
              "      <td>204.097733</td>\n",
              "      <td>413.086700</td>\n",
              "      <td>560.627258</td>\n",
              "      <td>232.582809</td>\n",
              "      <td>-54.543732</td>\n",
              "      <td>702.527588</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a96aec4-4ebb-4aad-9ad4-c528a309af1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a96aec4-4ebb-4aad-9ad4-c528a309af1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a96aec4-4ebb-4aad-9ad4-c528a309af1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZDtaVfjs2s9"
      },
      "source": [
        "#data.drop(['level_0'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pu3gXCAu4gy"
      },
      "source": [
        "- Splitting data into predictors and real values.\n",
        "- OneHotEncoding on the \"type\" feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9WcPqvcrw-g"
      },
      "source": [
        "def hour_prediction_data(data, drop_features=[]):\n",
        "  if granularity=='60min':\n",
        "    drop_features.extend(['energy_next_hour','energy_hour_2','energy_hour_3'])\n",
        "    X = data.drop(drop_features,axis=1)\n",
        "    Y = data[['energy_next_hour','energy_hour_2','energy_hour_3']]\n",
        "    if 'type' in drop_features:\n",
        "      return X,Y\n",
        "    else:\n",
        "      X_e = pd.get_dummies(X, columns=[\"type\"])\n",
        "      return X_e,Y\n",
        "  else:\n",
        "    return 0,0\n",
        "def min_prediction_data(data, drop_features=[]):\n",
        "  if granularity=='5min':\n",
        "    drop_features.extend(['energy_5_min','energy_15_min','energy_10_min','energy_next_hour','energy_hour_2','energy_hour_3',\\\n",
        "                          'energy_per_hour','energy_previous_hour','energy_hour_diff'])\n",
        "    x = data.drop(drop_features,axis=1)\n",
        "    y = data[['energy_5_min','energy_10_min','energy_15_min']]\n",
        "    if 'type' in drop_features:\n",
        "      return x,y\n",
        "    else:\n",
        "      x_e = pd.get_dummies(x, columns=[\"type\"])\n",
        "    return x_e,y\n",
        "  else:\n",
        "    return 0,0\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xY3rRvuuR2N"
      },
      "source": [
        "X,Y = hour_prediction_data(data)\n",
        "x,y = min_prediction_data(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu2BC7eaK9oQ"
      },
      "source": [
        "- Data used for training each house individually (houses).\n",
        "- Dropping features that are not usefull when predicting on individual houses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeDxlfxQVnjA"
      },
      "source": [
        "def indiv_house_data(house_dict, drop_features=[]):\n",
        "  drop_features.extend(['type','energy_Wh_houseMean'])\n",
        "  for i in range(1,len(house)+1,1):\n",
        "    house_dict[str(i)].drop(drop_features,axis=1,inplace=True)\n",
        "    house_dict[str(i)].dropna(inplace=True)\n",
        "  return house_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVwiDj_5G9b1"
      },
      "source": [
        "#if granularity == '5min':\n",
        "houses = indiv_house_data(house)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUhjyAWpKzVy"
      },
      "source": [
        "- Data used for training when all houses are aggregated, predictions 1-3 hours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5CpYfWaL9Fq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "outputId": "e12bf505-7fee-409c-b4ef-abb52a20ca8b"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     energy_Wh  max_air_temp  min_air_temp  energy_Wh_daymean  \\\n",
              "index                                                                           \n",
              "2012-11-11 00:00:00        181           9.4           4.1         560.627258   \n",
              "2012-11-11 01:00:00        225           9.4           4.1         560.627258   \n",
              "2012-11-11 02:00:00        192           9.4           4.1         560.627258   \n",
              "2012-11-11 03:00:00        232           9.4           4.1         560.627258   \n",
              "2012-11-11 04:00:00        178           9.4           4.1         560.627258   \n",
              "...                        ...           ...           ...                ...   \n",
              "2014-11-13 10:00:00        888           9.2           7.1        1014.129333   \n",
              "2014-11-13 11:00:00        934           9.2           7.1        1014.129333   \n",
              "2014-11-13 12:00:00       2823           9.2           7.1        1014.129333   \n",
              "2014-11-13 13:00:00       1199           9.2           7.1        1014.129333   \n",
              "2014-11-13 14:00:00       2329           9.2           7.1        1014.129333   \n",
              "\n",
              "                     energy_previous_hour  energy_diff  energy_Wh_houseMean  \\\n",
              "index                                                                         \n",
              "2012-11-11 00:00:00            184.402435    -3.127960           702.527588   \n",
              "2012-11-11 01:00:00            181.274475    44.085098           702.527588   \n",
              "2012-11-11 02:00:00            225.359573   -33.217728           702.527588   \n",
              "2012-11-11 03:00:00            192.141846    40.440964           702.527588   \n",
              "2012-11-11 04:00:00            232.582809   -54.543732           702.527588   \n",
              "...                                   ...          ...                  ...   \n",
              "2014-11-13 10:00:00            827.150146    61.167542          1078.384277   \n",
              "2014-11-13 11:00:00            888.317688    46.355774          1078.384277   \n",
              "2014-11-13 12:00:00            934.673462  1889.303833          1078.384277   \n",
              "2014-11-13 13:00:00           2823.977295 -1624.763184          1078.384277   \n",
              "2014-11-13 14:00:00           1199.214111  1130.758057          1078.384277   \n",
              "\n",
              "                     part_of_day  part_of_year  weekend  type_0  \\\n",
              "index                                                             \n",
              "2012-11-11 00:00:00            0             1        1       0   \n",
              "2012-11-11 01:00:00            0             1        1       0   \n",
              "2012-11-11 02:00:00            0             1        1       0   \n",
              "2012-11-11 03:00:00            0             1        1       0   \n",
              "2012-11-11 04:00:00            0             1        1       0   \n",
              "...                          ...           ...      ...     ...   \n",
              "2014-11-13 10:00:00            2             1        0       0   \n",
              "2014-11-13 11:00:00            2             1        0       0   \n",
              "2014-11-13 12:00:00            2             1        0       0   \n",
              "2014-11-13 13:00:00            2             1        0       0   \n",
              "2014-11-13 14:00:00            2             1        0       0   \n",
              "\n",
              "                     type_end-of-terrace  type_flat  type_mid-terrace  \n",
              "index                                                                  \n",
              "2012-11-11 00:00:00                    1          0                 0  \n",
              "2012-11-11 01:00:00                    1          0                 0  \n",
              "2012-11-11 02:00:00                    1          0                 0  \n",
              "2012-11-11 03:00:00                    1          0                 0  \n",
              "2012-11-11 04:00:00                    1          0                 0  \n",
              "...                                  ...        ...               ...  \n",
              "2014-11-13 10:00:00                    0          1                 0  \n",
              "2014-11-13 11:00:00                    0          1                 0  \n",
              "2014-11-13 12:00:00                    0          1                 0  \n",
              "2014-11-13 13:00:00                    0          1                 0  \n",
              "2014-11-13 14:00:00                    0          1                 0  \n",
              "\n",
              "[50429 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a20b612a-a63a-4e6f-951c-dc735a2bbea1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>energy_Wh</th>\n",
              "      <th>max_air_temp</th>\n",
              "      <th>min_air_temp</th>\n",
              "      <th>energy_Wh_daymean</th>\n",
              "      <th>energy_previous_hour</th>\n",
              "      <th>energy_diff</th>\n",
              "      <th>energy_Wh_houseMean</th>\n",
              "      <th>part_of_day</th>\n",
              "      <th>part_of_year</th>\n",
              "      <th>weekend</th>\n",
              "      <th>type_0</th>\n",
              "      <th>type_end-of-terrace</th>\n",
              "      <th>type_flat</th>\n",
              "      <th>type_mid-terrace</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-11-11 00:00:00</th>\n",
              "      <td>181</td>\n",
              "      <td>9.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>560.627258</td>\n",
              "      <td>184.402435</td>\n",
              "      <td>-3.127960</td>\n",
              "      <td>702.527588</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 01:00:00</th>\n",
              "      <td>225</td>\n",
              "      <td>9.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>560.627258</td>\n",
              "      <td>181.274475</td>\n",
              "      <td>44.085098</td>\n",
              "      <td>702.527588</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 02:00:00</th>\n",
              "      <td>192</td>\n",
              "      <td>9.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>560.627258</td>\n",
              "      <td>225.359573</td>\n",
              "      <td>-33.217728</td>\n",
              "      <td>702.527588</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 03:00:00</th>\n",
              "      <td>232</td>\n",
              "      <td>9.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>560.627258</td>\n",
              "      <td>192.141846</td>\n",
              "      <td>40.440964</td>\n",
              "      <td>702.527588</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 04:00:00</th>\n",
              "      <td>178</td>\n",
              "      <td>9.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>560.627258</td>\n",
              "      <td>232.582809</td>\n",
              "      <td>-54.543732</td>\n",
              "      <td>702.527588</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13 10:00:00</th>\n",
              "      <td>888</td>\n",
              "      <td>9.2</td>\n",
              "      <td>7.1</td>\n",
              "      <td>1014.129333</td>\n",
              "      <td>827.150146</td>\n",
              "      <td>61.167542</td>\n",
              "      <td>1078.384277</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13 11:00:00</th>\n",
              "      <td>934</td>\n",
              "      <td>9.2</td>\n",
              "      <td>7.1</td>\n",
              "      <td>1014.129333</td>\n",
              "      <td>888.317688</td>\n",
              "      <td>46.355774</td>\n",
              "      <td>1078.384277</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13 12:00:00</th>\n",
              "      <td>2823</td>\n",
              "      <td>9.2</td>\n",
              "      <td>7.1</td>\n",
              "      <td>1014.129333</td>\n",
              "      <td>934.673462</td>\n",
              "      <td>1889.303833</td>\n",
              "      <td>1078.384277</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13 13:00:00</th>\n",
              "      <td>1199</td>\n",
              "      <td>9.2</td>\n",
              "      <td>7.1</td>\n",
              "      <td>1014.129333</td>\n",
              "      <td>2823.977295</td>\n",
              "      <td>-1624.763184</td>\n",
              "      <td>1078.384277</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13 14:00:00</th>\n",
              "      <td>2329</td>\n",
              "      <td>9.2</td>\n",
              "      <td>7.1</td>\n",
              "      <td>1014.129333</td>\n",
              "      <td>1199.214111</td>\n",
              "      <td>1130.758057</td>\n",
              "      <td>1078.384277</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50429 rows  14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a20b612a-a63a-4e6f-951c-dc735a2bbea1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a20b612a-a63a-4e6f-951c-dc735a2bbea1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a20b612a-a63a-4e6f-951c-dc735a2bbea1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOLS-GSOkMqV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "e2951f73-6955-450b-b623-f450ab379ebc"
      },
      "source": [
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     energy_next_hour  energy_hour_2  energy_hour_3\n",
              "index                                                              \n",
              "2012-11-11 00:00:00        225.359573     192.141846     232.582809\n",
              "2012-11-11 01:00:00        192.141846     232.582809     178.039078\n",
              "2012-11-11 02:00:00        232.582809     178.039078     258.700439\n",
              "2012-11-11 03:00:00        178.039078     258.700439     204.097733\n",
              "2012-11-11 04:00:00        258.700439     204.097733     413.086700\n",
              "...                               ...            ...            ...\n",
              "2014-11-13 10:00:00        934.673462    2823.977295    1199.214111\n",
              "2014-11-13 11:00:00       2823.977295    1199.214111    2329.972168\n",
              "2014-11-13 12:00:00       1199.214111    2329.972168    1198.886230\n",
              "2014-11-13 13:00:00       2329.972168    1198.886230    1732.475220\n",
              "2014-11-13 14:00:00       1198.886230    1732.475220    1141.489746\n",
              "\n",
              "[50429 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-015fdf3f-0d21-4009-ae16-fb3bd5ef4976\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>energy_next_hour</th>\n",
              "      <th>energy_hour_2</th>\n",
              "      <th>energy_hour_3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-11-11 00:00:00</th>\n",
              "      <td>225.359573</td>\n",
              "      <td>192.141846</td>\n",
              "      <td>232.582809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 01:00:00</th>\n",
              "      <td>192.141846</td>\n",
              "      <td>232.582809</td>\n",
              "      <td>178.039078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 02:00:00</th>\n",
              "      <td>232.582809</td>\n",
              "      <td>178.039078</td>\n",
              "      <td>258.700439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 03:00:00</th>\n",
              "      <td>178.039078</td>\n",
              "      <td>258.700439</td>\n",
              "      <td>204.097733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 04:00:00</th>\n",
              "      <td>258.700439</td>\n",
              "      <td>204.097733</td>\n",
              "      <td>413.086700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13 10:00:00</th>\n",
              "      <td>934.673462</td>\n",
              "      <td>2823.977295</td>\n",
              "      <td>1199.214111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13 11:00:00</th>\n",
              "      <td>2823.977295</td>\n",
              "      <td>1199.214111</td>\n",
              "      <td>2329.972168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13 12:00:00</th>\n",
              "      <td>1199.214111</td>\n",
              "      <td>2329.972168</td>\n",
              "      <td>1198.886230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13 13:00:00</th>\n",
              "      <td>2329.972168</td>\n",
              "      <td>1198.886230</td>\n",
              "      <td>1732.475220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13 14:00:00</th>\n",
              "      <td>1198.886230</td>\n",
              "      <td>1732.475220</td>\n",
              "      <td>1141.489746</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50429 rows  3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-015fdf3f-0d21-4009-ae16-fb3bd5ef4976')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-015fdf3f-0d21-4009-ae16-fb3bd5ef4976 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-015fdf3f-0d21-4009-ae16-fb3bd5ef4976');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T46qwnF7KSdR"
      },
      "source": [
        "- Data used for training when all houses are aggregated, predictions 5-15 mins."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhUjsE_8Kmei"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOdpuYP7Knfk"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfHkWV8zKrSI"
      },
      "source": [
        "- Data used for RNN LSTM model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIwa0wCKx9cn"
      },
      "source": [
        "if granularity == '5min':\n",
        "  dataLSTM = X.drop(['energy_per_hour', 'energy_previous_hour','energy_hour_diff'],axis=1)\n",
        "  dataLSTM.head()\n",
        "if granularity == '60min':\n",
        "  dataLSTM = data.drop(['energy_next_hour','energy_hour_2','energy_hour_3'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQjKJpH2OJUK"
      },
      "source": [
        "- Pickling out data before deleting variables in case of later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X412l7wTI_Ix"
      },
      "source": [
        "if granularity == '5min':\n",
        "  name_tag = ['house','dataLSTM','houses','X','Y','x','y']\n",
        "  data_array = [house,dataLSTM,houses,X,Y,x,y]\n",
        "\n",
        "  pickle_out = {}\n",
        "  i=0\n",
        "  for t in name_tag:\n",
        "    pickle_out[t] = open(t+'.pkl','wb')\n",
        "    pickle.dump(data_array[i],pickle_out[t])\n",
        "    pickle_out[t].close()\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYBnw5MFP6Z8"
      },
      "source": [
        "def reload_data(name_tag):\n",
        "  pickle_in = {}\n",
        "  for t in name_tag:\n",
        "   pickle_in[t] = open(t+'.pkl','rb')\n",
        "  house = pickle.load(pickle_in['house'])\n",
        "  dataLSTM = pickle.load(pickle_in['dataLSTM'])\n",
        "  houses = pickle.load(pickle_in['houses'])\n",
        "  X = pickle.load(pickle_in['X'])\n",
        "  Y = pickle.load(pickle_in['Y'])\n",
        "  x = pickle.load(pickle_in['x'])\n",
        "  y = pickle.load(pickle_in['y'])\n",
        "  return house,dataLSTM,houses,X,Y,x,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY681O7KGNNS"
      },
      "source": [
        "- I used the recurrent neural network to predict one sample ahead, so 5 minutes into the future.\n",
        "- When optimizing the recurrent neural network model I tried different number of units for the LSTM layer, I also tried a stacked LSTM with two LSTM layers, which was alot more prone to overfitting and slower to train. At the end I went for 32 units which didn't overfit, while also learning the model pretty decently.\n",
        "- I included a Dropout layer, which helped with overfitting.\n",
        "- I also tweaked the n_past parameter, the more samples I took, the longer was the training time, I found many different values which gave roughly the same result and chose 5 in the end, because it was the fastest.\n",
        "- Because there was no signs of overfitting, I tried doing up to 30 epochs when the reults weren't getting better or worse anymore.\n",
        "- At the end, I graphed out the plot, showing my training loss compared to the loss on the test set, which helped me see, if my model was overfitting or underfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef8aOsF6Ovl8"
      },
      "source": [
        "def RNN_LSTM(data, n_future, n_past):\n",
        "  # scaling the data\n",
        "  scaler = StandardScaler()\n",
        "  scaler = scaler.fit(data)\n",
        "  x_e = scaler.transform(data)\n",
        "\n",
        "  X = []\n",
        "  Y = []\n",
        "\n",
        "  # Reshaping the data so I can feed it into the LSTM RNN. Shape of the data looks like \n",
        "  # (number of samples, n_past, number of features) where n_past is the number of previous\n",
        "  # samples we use to predict the next value and n_future is how many values ahead do we want to predict.  \n",
        "  for i in range(n_past, len(x_e) - n_future +1):\n",
        "    X.append(x_e[i - n_past:i, 0:x_e.shape[1]])\n",
        "    Y.append(x_e[i + n_future - 1:i + n_future, 0])\n",
        "\n",
        "  X, Y = np.array(X), np.array(Y)\n",
        "\n",
        "  x_train,x_test,y_train,y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)\n",
        "  x_train, x_test, y_train, y_test = np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test)\n",
        "\n",
        "  # Checkpoint saves the state of the model at the epoch where it's performing the best.\n",
        "  checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "  checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "  callbacks_list = [checkpoint]\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(32, activation='relu', input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=False))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(Y.shape[1]))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='mae',metrics=['mean_absolute_error'])\n",
        "  model.summary()\n",
        "\n",
        "  # fit the model\n",
        "  history = model.fit(x_train, y_train, epochs=30,batch_size=16,validation_split=0.1, verbose=1, callbacks=callbacks_list)\n",
        "\n",
        "  plt.plot(history.history['loss'], label='Training loss')\n",
        "  plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "  plt.legend()\n",
        "\n",
        "  # make predictions\n",
        "  trainPredict = model.predict(x_train)\n",
        "  testPredict = model.predict(x_test)\n",
        "  # invert predictions\n",
        "  trainPredict_copies = np.repeat(trainPredict, x_e.shape[1], axis=-1)\n",
        "  trainPredict = scaler.inverse_transform(trainPredict_copies)[:,0]\n",
        "  y_train_copies = np.repeat(y_train, x_e.shape[1], axis=-1)\n",
        "  y_train = scaler.inverse_transform(y_train_copies)[:,0]\n",
        "  testPredict_copies = np.repeat(testPredict, x_e.shape[1], axis=-1)\n",
        "  testPredict = scaler.inverse_transform(testPredict_copies)[:,0]\n",
        "  y_test_copies = np.repeat(y_test, x_e.shape[1], axis=-1)\n",
        "  y_test = scaler.inverse_transform(y_test_copies)[:,0]\n",
        "  # calculate and print mean absolute error\n",
        "  trainScore = mean_absolute_error(y_train, trainPredict)\n",
        "  print('Train Score: %.2f MAE' % (trainScore))\n",
        "  testScore = mean_absolute_error(y_test, testPredict)\n",
        "  print('Test Score: %.2f MAE' % (testScore))\n",
        "\n",
        "  return trainScore,testScore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xauWqQlATkDp"
      },
      "source": [
        "if granularity == '5min':\n",
        "  house,dataLSTM,houses,X,Y,x,y = reload_data(name_tag)\n",
        "  del X,Y,houses,x,y,house\n",
        "else:\n",
        "  dataLSTM = pd.get_dummies(dataLSTM, columns=[\"type\"])\n",
        "RNN_LSTM(data=dataLSTM,n_future=3,n_past=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if granularity == '5min':\n",
        "  pass\n",
        "else:\n",
        "  ."
      ],
      "metadata": {
        "id": "9yURzsrVXBDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN LSTM prediction on each house individually 5min, 10min, 15min and 1 hour, 2 hours, 3 hours"
      ],
      "metadata": {
        "id": "xAz04iSn_JdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if granularity=='5min':\n",
        "  house,dataLSTM,houses,X,Y,x,y = reload_data(name_tag)\n",
        "  del X,Y,dataLSTM,x,y,house\n",
        "  for i in range(1,len(houses)+1,1):\n",
        "    RNN_LSTM(data=houses[str(i)].drop(['energy_per_hour', 'energy_previous_hour','energy_hour_diff','energy_hour_2','energy_hour_3','energy_hour_diff','energy_5_min','energy_10_min',\\\n",
        "                        'energy_15_min','energy_next_hour'],axis=1),n_future=3,n_past=5)\n",
        "else:\n",
        "  for i in range(1,len(houses)+1,1):\n",
        "    RNN_LSTM(data=houses[str(i)].drop(['energy_next_hour', 'energy_previous_hour','energy_hour_2','energy_hour_3'],axis=1),n_future=1,n_past=5)\n",
        "    "
      ],
      "metadata": {
        "id": "mtzfec6L79hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "n_future = 2, 220,90 MAE\n",
        "\n",
        "n_future = 3, 240,71 MAE"
      ],
      "metadata": {
        "id": "kPsqHAf9wIkl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrU0BpHRPLzC"
      },
      "source": [
        "- Results using RNN LSTM (mean absolute error in Wh):\n",
        "  - Prediction 5 minutes:\n",
        "    - Train Score: 174.30 MAE\n",
        "    - Test Score: 172.11 MAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KecZtMhiPodd"
      },
      "source": [
        "*in progress*\n",
        "- Plotting the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeHDFUiCP3cv"
      },
      "source": [
        "'''# shift train predictions for plotting\n",
        "trainPredictPlot = numpy.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "# plot baseline and predictions\n",
        "plt.plot(scaler.inverse_transform(dataset))\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moARz3m_EtZy"
      },
      "source": [
        "*in progress*\n",
        "- Writing a custom loss function, so I can punish the undershooting mistakes more than overshooting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvhVyzhRlL7N"
      },
      "source": [
        "'''\n",
        "def custom_f(predt, dtrain):\n",
        "    alpha = 1.5\n",
        "    #y = dtrain.get_label()\n",
        "    if predt-dtrain<0:\n",
        "      return -alpha*np.abs(predt-dtrain)\n",
        "    else:\n",
        "      return -np.abs(predt-dtrain)'''\n",
        "'''\n",
        "def gradient(predt: np.ndarray, dtrain: xgb.DMatrix) -> np.ndarray:\n",
        "    #Compute the gradient squared log error.\n",
        "    y = dtrain.get_label()\n",
        "    return (np.log1p(predt) - np.log1p(y)) / (predt + 1)\n",
        "\n",
        "def hessian(predt: np.ndarray, dtrain: xgb.DMatrix) -> np.ndarray:\n",
        "    #Compute the hessian for squared log error.\n",
        "    y = dtrain.get_label()\n",
        "    return ((-np.log1p(predt) + np.log1p(y) + 1) /\n",
        "            np.power(predt + 1, 2))\n",
        "\n",
        "def squared_log(predt: np.ndarray,\n",
        "                dtrain: xgb.DMatrix) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    #Squared Log Error objective. A simplified version for RMSLE used as objective function.\n",
        "    \n",
        "    predt[predt < -1] = -1 + 1e-6\n",
        "    grad = gradient(predt, dtrain)\n",
        "    hess = hessian(predt, dtrain)\n",
        "    return grad, hess'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yENA2ASoIw_C"
      },
      "source": [
        "labels = ['energy_next_hour','energy_hour_2','energy_hour_3']\n",
        "labels2 = ['energy_5_min','energy_10_min','energy_15_min']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpH7PSoxFOX0"
      },
      "source": [
        "- With the XGboost model, I was using two different datasets. One was the same as with the recurrent neural network, where I predict for 5 minutes ahead. For the other one I also did predictions for one hour, two and three hours ahead, similar to what I was doing on the Reach dataset.\n",
        "- Testing out the XGBoost model:\n",
        "  - For adjusting the hyperparameters I used GridSearchCV.\n",
        "  - For most of my training I set n_estimators to equal 10. I did this to save time, while not losing that much on the accuracy of the model.\n",
        "- Best results (mean absolute error in Wh):\n",
        "  - dataset 1:\n",
        "    - 5 minutes: 267.45 MAE\n",
        "    - 10 minutes: 282.61 MAE\n",
        "    - 15 minutes: 290.68 MAE\n",
        "  - dataset 2:\n",
        "    - 1 hour: 243.61 MAE\n",
        "    - 2 hours: 247.92 MAE\n",
        "    - 3 hours: 246.93 MAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW8nJEagbyQu"
      },
      "source": [
        "def XGB_aggreg_hour(X,Y):\n",
        "  xgb_regr = xgb.XGBRegressor(verbose=1,gamma=0,max_depth=25,min_child_weight=10,n_jobs=-1,n_estimators=10)\n",
        "  resultsXGB = []\n",
        "  shiftsXGB = []\n",
        "  print(\"HOURS:\")\n",
        "  for l in labels:\n",
        "    kfold = KFold(n_splits=4,shuffle=True)\n",
        "    results = cross_val_score(xgb_regr,X,Y[l],cv=kfold,scoring='neg_mean_absolute_error')\n",
        "    print(f\"Mean, std: {results.mean()}, {results.std()}\")\n",
        "    shiftsXGB.append(results.mean())\n",
        "  resultsXGB.append(shiftsXGB)\n",
        "  print(f\"results hours: {resultsXGB}\")\n",
        "\n",
        "  return resultsXGB\n",
        "\n",
        "def XGB_aggreg_min(x,y):\n",
        "  xgb_regr = xgb.XGBRegressor(verbose=1,gamma=0,max_depth=8,min_child_weight=14,n_jobs=-1,n_estimators=10)\n",
        "  resultsXGB_min = []\n",
        "  shiftsXGB = []\n",
        "  print(\"MINUTES:\")\n",
        "  for l in labels2:\n",
        "    kfold = KFold(n_splits=4,shuffle=True)\n",
        "    results = cross_val_score(xgb_regr,x,y[l],cv=kfold,scoring='neg_mean_absolute_error')\n",
        "    print(f\"Mean, std: {results.mean()}, {results.std()}\")\n",
        "    shiftsXGB.append(results.mean())\n",
        "  resultsXGB_min.append(shiftsXGB)\n",
        "\n",
        "  print(f\"results minutes: {resultsXGB_min}\")\n",
        "  \n",
        "  return resultsXGB_min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsNVPaXdd7c0"
      },
      "source": [
        "house,dataLSTM,houses,X,Y,x,y = reload_data(name_tag)\n",
        "del houses,house,dataLSTM,x,y\n",
        "XGB_aggreg_hours(X,Y)\n",
        "\n",
        "house,dataLSTM,houses,X,Y,x,y = reload_data(name_tag)\n",
        "del houses,house,dataLSTM,X,Y\n",
        "XGB_aggreg_min(x,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4QTHH06Zuc-"
      },
      "source": [
        "- I did results for every house individually aswell. I did a similar thing as before where I used two different datasets one for predicting 5 minutes ahead and the other for 1-3 hours ahead. First I did it with RandomForestRegressor, which I optimized using GridSearchCV.\n",
        "- The results of two seperate trainings are listed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhg-y3FqTsj3"
      },
      "source": [
        "def RF_indiv_hour(houses): \n",
        "  RF_regr = RandomForestRegressor(n_estimators=10)\n",
        "  results_every_house = []\n",
        "  for i in range(1,len(houses)+1,1):\n",
        "    shifts_every_house = []\n",
        "    for l in labels:\n",
        "      kfold = KFold(n_splits=4, shuffle=True, random_state=42)\n",
        "      results = cross_val_score(RF_regr,houses[str(i)].drop(['energy_next_hour','energy_hour_2','energy_hour_3','energy_5_min','energy_10_min','energy_15_min'],axis=1),\\\n",
        "                              houses[str(i)][l],cv=kfold,scoring='neg_mean_absolute_error')\n",
        "      #print(f\"Mean,std: {results.mean()}, {results.std()}\")\n",
        "      shifts_every_house.append(results.mean())\n",
        "    results_every_house.append(shifts_every_house)\n",
        "  return results_every_house\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxQpz2QqPF_R"
      },
      "source": [
        "def RF_indiv_min(houses):\n",
        "  RF_regr = RandomForestRegressor(n_estimators=10)\n",
        "  results_every_house_min = []\n",
        "  for i in range(1,len(houses)+1,1):\n",
        "    shifts_every_house = []\n",
        "    for l in labels2:\n",
        "      kfold = KFold(n_splits=4, shuffle=True, random_state=42)\n",
        "      results = cross_val_score(RF_regr,houses[str(i)].drop(['energy_next_hour','energy_hour_2','energy_hour_3','energy_5_min','energy_10_min','energy_15_min'],axis=1),\\\n",
        "                              houses[str(i)][l],cv=kfold,scoring='neg_mean_absolute_error')\n",
        "      #print(f\"Mean,std: {results.mean()}, {results.std()}\")\n",
        "      shifts_every_house.append(results.mean())\n",
        "    results_every_house_min.append(shifts_every_house)\n",
        "  return results_every_house_min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "770wiAnTdwUp"
      },
      "source": [
        "house,dataLSTM,houses,X,Y,x,y = reload_data(name_tag)\n",
        "del house,dataLSTM,X,Y,x,y\n",
        "\n",
        "RF_indiv_hour(houses)\n",
        "RF_indiv_min(houses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-x_cp0jF-fp"
      },
      "source": [
        "- The results using RandomForestRegressor (negative MAE in Wh) for each of the five houses.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cryvn0tUYydW"
      },
      "source": [
        "# Hour shifts of 1, 2 and 3 for each house\n",
        "res1 = [[-8.940321554901315, -5.907694852169678, -6.081659686491101],\n",
        " [-3.1259870620033503, -3.3141521606969047, -2.7314996533381835],\n",
        " [-16.634527979399458, -9.018266701288404, -8.445598022745479],\n",
        " [-2.53823452536365, -2.5633788857156032, -3.616244763433274],\n",
        " [-4.35738370942241, -4.0452113971608945, -4.529010026977254]]\n",
        "\n",
        "res2 = [[-9.147939178881995, -5.61363458901363, -5.631915073723677],\n",
        " [-3.069280121205534, -3.4800966887110203, -2.6198912478655654],\n",
        " [-17.04767340492508, -11.202566931669569, -8.768770778505989],\n",
        " [-2.644403943231151, -2.6088597424836477, -3.4567297063981623],\n",
        " [-3.249339643759429, -4.2898561738367125, -4.844694880434709]]\n",
        "\n",
        "# Prediction for 5, 10 and 15 minutes ahead\n",
        "res3 = [[-205.21729301043933, -264.68734899936373, -278.7132719689562],\n",
        " [-178.5423738333146, -224.1490214555531, -232.40861009156316],\n",
        " [-133.84860141265835, -178.22609567867588, -199.03604223464993],\n",
        " [-173.63488655849287, -210.0114049618994, -219.1221518750832],\n",
        " [-170.43731613068456, -227.50765566239184, -243.22578830127958]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqZJsEfna9yM"
      },
      "source": [
        "- Then I tried it with XGBRegressor aswell.\n",
        "- Results are listed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O-Qu1Ngax-0"
      },
      "source": [
        "def XGB_indiv_hour(houses):\n",
        "  xgb_regr = xgb.XGBRegressor(verbose=1,gamma=0,max_depth=25,min_child_weight=10,n_jobs=-1,n_estimators=10)\n",
        "  results_every_house = []\n",
        "  for i in range(1,len(houses)+1,1):\n",
        "    shifts_every_house = []\n",
        "    for l in labels:\n",
        "      kfold = KFold(n_splits=4, shuffle=True, random_state=42)\n",
        "      results = cross_val_score(xgb_regr,houses[str(i)].drop(['energy_next_hour','energy_hour_2','energy_hour_3','energy_5_min','energy_10_min','energy_15_min'], axis=1),\\\n",
        "                              houses[str(i)][l],cv=kfold,scoring='neg_mean_absolute_error')\n",
        "      #print(f\"Mean,std: {results.mean()}, {results.std()}\")\n",
        "      shifts_every_house.append(results.mean())\n",
        "    results_every_house.append(shifts_every_house)\n",
        "  print(f\"Results hour: {results_every_house}\")\n",
        "  return results_every_house"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3zCQDnTQ3Iw"
      },
      "source": [
        "def XGB_indiv_min(houses):\n",
        "  xgb_regr = xgb.XGBRegressor(verbose=1,gamma=0,max_depth=8,min_child_weight=14,n_jobs=-1,n_estimators=10)\n",
        "  results_every_house_min = []\n",
        "  for i in range(1,len(houses)+1,1):\n",
        "    shifts_every_house = []\n",
        "    for l in labels2:\n",
        "      kfold = KFold(n_splits=4, shuffle=True, random_state=42)\n",
        "      results = cross_val_score(xgb_regr,houses[str(i)].drop(['energy_next_hour','energy_hour_2','energy_hour_3','energy_5_min','energy_10_min','energy_15_min'], axis=1),\\\n",
        "                              houses[str(i)][l],cv=kfold,scoring='neg_mean_absolute_error')\n",
        "      #print(f\"Mean,std: {results.mean()}, {results.std()}\")\n",
        "      shifts_every_house.append(results.mean())\n",
        "    results_every_house_min.append(shifts_every_house)\n",
        "  print(f\"Results min: {results_every_house_min}\")\n",
        "  return results_every_house_min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyti7H5siUdM"
      },
      "source": [
        "XGB_indiv_hour(houses)\n",
        "XGB_indiv_min(houses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCFkx9SDibdO"
      },
      "source": [
        "- The results using XGBRegressor (negative MAE in Wh) for each of the five houses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AukAWepzicBX"
      },
      "source": [
        "# Hours shifts of 1, 2 and 3 for each house\n",
        "res = [[-244.98690032958984, -251.21905517578125, -253.93219375610352],\n",
        " [-180.08655166625977, -181.13837051391602, -181.60640335083008],\n",
        " [-237.07272338867188, -250.8828125, -250.80009078979492],\n",
        " [-194.4733657836914, -195.52861404418945, -195.61228942871094],\n",
        " [-380.97105407714844, -382.78367614746094, -382.90311431884766]]\n",
        "# Prediction for 5, 10 and 15 minutes ahead\n",
        "res2 = [[-267.6378173828125, -291.14539337158203, -296.9206848144531],\n",
        " [-208.86071014404297, -228.75857543945312, -232.5463638305664],\n",
        " [-244.11033630371094, -262.56711196899414, -273.9931869506836],\n",
        " [-214.06250381469727, -227.1177635192871, -233.57318878173828],\n",
        " [-387.7323226928711, -401.28368377685547, -406.7476348876953]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XKeMAEEbUb-"
      },
      "source": [
        "- Here, I did the same predictions as with XGBoost on all houses aggregated, using RandomForestRegressor.\n",
        "- Best results (mean absolute error in Wh):\n",
        "  - dataset 1:\n",
        "    - 5 minutes: 199.00 MAE\n",
        "    - 10 minutes: 183.54 MAE\n",
        "    - 15 minutes: 198.02 MAE\n",
        "  - dataset 2:\n",
        "    - 1 hour: 5.75 MAE\n",
        "    - 2 hours: 3.57 MAE\n",
        "    - 3 hours: 4.62 MAE\n",
        "\n",
        "- We can see that the last 3 results are suspiciously good, and probably a result of overfitting, even though I used cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aYSkV9BT0Dg"
      },
      "source": [
        "def RF_aggreg_hour(X,Y):  \n",
        "  RF_regr = RandomForestRegressor(n_estimators=10)\n",
        "  resultsRF = []\n",
        "  shiftsRF = []\n",
        "  for l in labels:\n",
        "    kfold = KFold(n_splits=4, shuffle=True)\n",
        "    results = cross_val_score(RF_regr,X,Y[l],cv=kfold,scoring='neg_mean_absolute_error')\n",
        "    print(f\"Mean,std: {results.mean()}, {results.std()}\")\n",
        "    shiftsRF.append(results.mean())\n",
        "  resultsRF.append(shiftsRF)\n",
        "  print(f\"Results hour: {resultsRF}\")\n",
        "  return resultsRF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5soRxnLSZFwK"
      },
      "source": [
        "def RF_aggreg_min(x,y):\n",
        "  RF_regr = RandomForestRegressor(n_estimators=10, min_samples_leaf=40, min_samples_split=20)\n",
        "  resultsRF_min = []\n",
        "  shiftsRF = []\n",
        "  for l in labels2:\n",
        "    kfold = KFold(n_splits=4, shuffle=True)\n",
        "    results = cross_val_score(RF_regr,x,y[l],cv=kfold,scoring='neg_mean_absolute_error')\n",
        "    print(f\"Mean,std: {results.mean()}, {results.std()}\")\n",
        "    shiftsRF.append(results.mean())\n",
        "  resultsRF_min.append(shiftsRF)\n",
        "  print(f\"Results min: {resultsRF_min}\")\n",
        "  return resultsRF_min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohWq2v1-ZHJi"
      },
      "source": [
        "house,dataLSTM,houses,X,Y,x,y = reload_data(name_tag)\n",
        "del houses,house,dataLSTM,x,y\n",
        "RF_aggreg_hour(X,Y)\n",
        "\n",
        "house,dataLSTM,houses,X,Y,x,y = reload_data(name_tag)\n",
        "del houses,house,dataLSTM,X,Y\n",
        "RF_aggreg_min(x,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbA_9nSAHaC8"
      },
      "source": [
        "- Results using RandomForestRegressor when all houses are aggregated (negative MAE)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qJkmFiXVFoW"
      },
      "source": [
        "# prediction 1, 2, 3 hours into the future:\n",
        "r1 = [-8.033944268003609, -7.22307783236139, -5.029273831055247]\n",
        "r2 = [-5.750566512889883, -3.5746119976256003, -4.625614552566425]\n",
        "\n",
        "# prediction 5, 10, 15 minutes into the future:\n",
        "r3 = [-201.79729266526888, -283.5402434192109, -298.02007765958325] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YeaaizzHi2T"
      },
      "source": [
        "- Optimizing hyperparameters using GridSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iT6qLi2f5Pj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e8db138-2047-4db9-8d98-d7fcee587d67"
      },
      "source": [
        "param_grid = {\n",
        "    'min_samples_split': [15,20,25],\n",
        "    'min_samples_leaf': [25,30,35,40,45,50]\n",
        "}\n",
        "kfold = KFold(n_splits=4, shuffle=True, random_state=0)\n",
        "clf =  GridSearchCV(RandomForestRegressor(n_estimators=10, n_jobs=-1),param_grid, cv=kfold, return_train_score=False,scoring='neg_mean_absolute_error')\n",
        "clf.fit(X,Y['energy_next_hour'])\n",
        "print(f'Best estimator: {clf.best_estimator_}')\n",
        "print(f'Best params: {clf.best_params_}')\n",
        "print(f'Best score: {clf.best_score_}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best estimator: RandomForestRegressor(min_samples_leaf=40, min_samples_split=25,\n",
            "                      n_estimators=10, n_jobs=-1)\n",
            "Best params: {'min_samples_leaf': 40, 'min_samples_split': 25}\n",
            "Best score: -271.1933033788696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "5bMyI2FTcK7J",
        "outputId": "d57893bb-cc20-4b94-b561-eeb5b8197d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     energy_next_hour  energy_hour_2  energy_hour_3\n",
              "index                                                              \n",
              "2012-11-11 00:00:00        225.359573     192.141846     232.582809\n",
              "2012-11-11 01:00:00        192.141846     232.582809     178.039078\n",
              "2012-11-11 02:00:00        232.582809     178.039078     258.700439\n",
              "2012-11-11 03:00:00        178.039078     258.700439     204.097733\n",
              "2012-11-11 04:00:00        258.700439     204.097733     413.086700\n",
              "...                               ...            ...            ...\n",
              "2014-11-13 10:00:00        934.673462    2823.977295    1199.214111\n",
              "2014-11-13 11:00:00       2823.977295    1199.214111    2329.972168\n",
              "2014-11-13 12:00:00       1199.214111    2329.972168    1198.886230\n",
              "2014-11-13 13:00:00       2329.972168    1198.886230    1732.475220\n",
              "2014-11-13 14:00:00       1198.886230    1732.475220    1141.489746\n",
              "\n",
              "[50429 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40508236-404c-4fae-bb00-276d94e0eb36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>energy_next_hour</th>\n",
              "      <th>energy_hour_2</th>\n",
              "      <th>energy_hour_3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-11-11 00:00:00</th>\n",
              "      <td>225.359573</td>\n",
              "      <td>192.141846</td>\n",
              "      <td>232.582809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 01:00:00</th>\n",
              "      <td>192.141846</td>\n",
              "      <td>232.582809</td>\n",
              "      <td>178.039078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 02:00:00</th>\n",
              "      <td>232.582809</td>\n",
              "      <td>178.039078</td>\n",
              "      <td>258.700439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 03:00:00</th>\n",
              "      <td>178.039078</td>\n",
              "      <td>258.700439</td>\n",
              "      <td>204.097733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-11-11 04:00:00</th>\n",
              "      <td>258.700439</td>\n",
              "      <td>204.097733</td>\n",
              "      <td>413.086700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13 10:00:00</th>\n",
              "      <td>934.673462</td>\n",
              "      <td>2823.977295</td>\n",
              "      <td>1199.214111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13 11:00:00</th>\n",
              "      <td>2823.977295</td>\n",
              "      <td>1199.214111</td>\n",
              "      <td>2329.972168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13 12:00:00</th>\n",
              "      <td>1199.214111</td>\n",
              "      <td>2329.972168</td>\n",
              "      <td>1198.886230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13 13:00:00</th>\n",
              "      <td>2329.972168</td>\n",
              "      <td>1198.886230</td>\n",
              "      <td>1732.475220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-13 14:00:00</th>\n",
              "      <td>1198.886230</td>\n",
              "      <td>1732.475220</td>\n",
              "      <td>1141.489746</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50429 rows  3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40508236-404c-4fae-bb00-276d94e0eb36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40508236-404c-4fae-bb00-276d94e0eb36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40508236-404c-4fae-bb00-276d94e0eb36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CCPTcDJHqH8"
      },
      "source": [
        "- Plotting out the graph of feature importances when predicting with RandomForestRegressor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmCUT4XIT-UN"
      },
      "source": [
        "feature_names = ['energy_Wh','max_air_temp','min_air_temp','energy_Wh_houseMean','energy_Wh_daymean','energy_per_hour','energy_previous_hour','energy_hour_diff','energy_diff',\\\n",
        "                 'part_of_day','part_of_year','weekend','type_0','type_eot','type_flat','type_mt']\n",
        "forest = RandomForestRegressor(n_estimators=10)\n",
        "forest.fit(X_e,Y)\n",
        "importances = forest.feature_importances_\n",
        "\n",
        "forest_importances = pd.DataFrame(importances, index=feature_names,columns=['importance']).sort_values('importance',ascending=False)\n",
        "\n",
        "plt.rcParams.update({'figure.figsize': (20, 10.0)})\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "plt.barh(feature_names, importances)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evMe5dSQH6uc"
      },
      "source": [
        "- Making predictions with the models, so I can later plot them on a graph.\n",
        "- Predictions and graphs are made predicting one hour into the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkZetEFpZqMy"
      },
      "source": [
        "house,dataLSTM,houses,X,Y,x,y = reload_data(name_tag)\n",
        "del x,y,house,dataLSTM,X,Y\n",
        "\n",
        "kfold = KFold(n_splits=4, shuffle=True, random_state=0)\n",
        "predictions_1=predictions_2=predictions_3=predictions_4=predictions_5=np.ndarray(0)\n",
        "house_predictions = [predictions_1,predictions_2,predictions_3,predictions_4,predictions_5]\n",
        "\n",
        "\n",
        "for i in range(0,len(houses),1):\n",
        "  house_predictions[i] = cross_val_predict(xgb.XGBRegressor(verbose=1,gamma=0,max_depth=25,min_child_weight=13,n_jobs=-1,n_estimators=10),\\\n",
        "                                    houses[str(i+1)].drop(['energy_next_hour','energy_hour_2','energy_hour_3','energy_5_min','energy_10_min','energy_15_min'],axis=1),\\\n",
        "                                    houses[str(i+1)]['energy_next_hour'], cv=kfold,n_jobs=-1,verbose=1)\n",
        "\n",
        "for i in range(0,len(houses),1):\n",
        "  house_predictions[i] = pd.DataFrame({'real':houses[str(i+1)].energy_next_hour,'pred':house_predictions[i]})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO_05WjoINPG"
      },
      "source": [
        "- Choosing a one week period in the data, so I can see the details in the lineplot, otherwise the data is too dense."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tba0fSI0LDm"
      },
      "source": [
        "# function drops index row, for graphing purposes\n",
        "def drop_index(dataset):\n",
        "  dataset = dataset.reset_index()\n",
        "  return dataset.drop(['index'], axis=1)\n",
        "\n",
        "# dataset for lineplot\n",
        "def make_lineplot(data, start_week, end_week):\n",
        "  lineplot = {}\n",
        "  i = 1\n",
        "  for p in data:\n",
        "    lineplot['House_'+str(i)] = p[start_week*168 : end_week*168]\n",
        "    lineplot['House_'+str(i)] = drop_index(lineplot['House_'+str(i)])\n",
        "    i+=1\n",
        "  return lineplot\n",
        "\n",
        "# dataset for kdeplot\n",
        "def make_kdeplot(data):\n",
        "  kdeplot = {}\n",
        "  i = 1\n",
        "  for p in data:\n",
        "    kdeplot['House_'+str(i)] = p\n",
        "    i+=1\n",
        "  return kdeplot\n",
        "\n",
        "def draw_kdeplot(house_data):\n",
        "  plt.figure(figsize=(15,15))\n",
        "  sns.kdeplot(x=house_data['real'],data=house_data)\n",
        "  sns.kdeplot(x=house_data['pred'],data=house_data)\n",
        "  plt.legend(['real','predicted'])\n",
        "\n",
        "def draw_lineplot(house_data):\n",
        "  plt.figure(figsize=(15,15))\n",
        "  sns.lineplot(x=house_data.index,y=house_data['real'],data=house_data)\n",
        "  sns.lineplot(x=house_data.index,y=house_data['pred'],data=house_data)\n",
        "  plt.legend(['real','predicted'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLsEh_Gl1uNo"
      },
      "source": [
        "lineplot = make_lineplot(house_predictions, 0, 2)\n",
        "kdeplot = make_kdeplot(house_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b6B08gSIoK2"
      },
      "source": [
        "- KDE plots for each house.\n",
        "  - Similar to the Reach data, again all plots show a common trait and that is, that they have two peaks in values. Although here I noticed that my model really overshoots the first peak and overall the prediction graph is slightly shifted to the left, which would mean that in general I undershoot the prediction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmQnPtZauG_"
      },
      "source": [
        "draw_kdeplot(kdeplot['House_1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ8f0Hlaaugq"
      },
      "source": [
        "draw_kdeplot(kdeplot['House_2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lx_uyh7au84"
      },
      "source": [
        "draw_kdeplot(kdeplot['House_3'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cgc0eEjMavQ6"
      },
      "source": [
        "draw_kdeplot(kdeplot['House_4'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3He4dyRavol"
      },
      "source": [
        "draw_kdeplot(kdeplot['House_5'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvse61MNItmY"
      },
      "source": [
        "- Lineplots of a one week period, including the real values of energy consumption and the predictions for each house.\n",
        "  - For this dataset I decided to show the graphs using XGBRegressor. I am quite happy with the general shape of the graph, although again I can clearly see that predictions aren't \"flexible\" enough in other words, I am undershooting the \"peaks\" of consumption and overshooting the \"valleys\". But even more obvious is that in general all my predictions are too low. I will try to fix that by writing a custom loss function, which will hopefully just shift the graph up.\n",
        "  - I also graphed out the results using RandomForestRegressor, although the graphs were alot better, because the fit was alot better I could still notice the \"flexibility\" problem, that I cannot fix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYV4LgMKbKyn"
      },
      "source": [
        "draw_lineplot(lineplot['House_1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT9aZlvdbLUI"
      },
      "source": [
        "draw_lineplot(lineplot['House_2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLb4FdKgbLw2"
      },
      "source": [
        "draw_lineplot(lineplot['House_3'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcufuoPHbMMy"
      },
      "source": [
        "draw_lineplot(lineplot['House_4'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs1gdlpRbMjg"
      },
      "source": [
        "draw_lineplot(lineplot['House_5'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}